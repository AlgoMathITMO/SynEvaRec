{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mysterious-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import random as npr\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3ed26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "BOOKS_DATASET_PATH = \"books_dataset_cleaned.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-yugoslavia",
   "metadata": {},
   "source": [
    "## Load and transform restaurants data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3adefce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108209</th>\n",
       "      <td>101876</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>0020199600</td>\n",
       "      <td>8</td>\n",
       "      <td>8.416667</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Scribner Paper Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136194</th>\n",
       "      <td>254224</td>\n",
       "      <td>37.958174</td>\n",
       "      <td>usa</td>\n",
       "      <td>067172262X</td>\n",
       "      <td>8</td>\n",
       "      <td>8.708333</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Washington Square Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236874</th>\n",
       "      <td>51883</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>0373272480</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>Mary Mcbride</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Silhouette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67363</th>\n",
       "      <td>5206</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>spain</td>\n",
       "      <td>8408048082</td>\n",
       "      <td>8</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>Paulo Coelho</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Planeta Pub Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123452</th>\n",
       "      <td>257493</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>0380820854</td>\n",
       "      <td>10</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>Julia Quinn</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Avon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        Age Country        ISBN  book_rating  rating_Avg  \\\n",
       "108209   101876  38.000000     usa  0020199600            8    8.416667   \n",
       "136194   254224  37.958174     usa  067172262X            8    8.708333   \n",
       "236874    51883  31.000000     usa  0373272480           10   10.000000   \n",
       "67363      5206  18.000000   spain  8408048082            8    7.500000   \n",
       "123452   257493  25.000000     usa  0380820854           10    7.500000   \n",
       "\n",
       "                Book_Author  Year_Of_Publication                Publisher  \n",
       "108209  F. Scott Fitzgerald               1988.0   Scribner Paper Fiction  \n",
       "136194  William Shakespeare               1992.0  Washington Square Press  \n",
       "236874         Mary Mcbride               2002.0               Silhouette  \n",
       "67363          Paulo Coelho               2003.0         Planeta Pub Corp  \n",
       "123452          Julia Quinn               2003.0                     Avon  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset = pd.read_csv(BOOKS_DATASET_PATH)\n",
    "real_dataset = real_dataset.drop([\"Location\", \"rating_sum\", \"Book_Title\", \"Count_All_Rate\"], axis=1)\n",
    "real_dataset = real_dataset.sample(frac=0.05)\n",
    "real_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52f367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset[\"ISBN\"] = real_dataset[\"ISBN\"].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd4c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset[\"book_rating\"] = real_dataset[\"book_rating\"] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a105d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                  int64\n",
       "Age                    float64\n",
       "Country                 object\n",
       "ISBN                     int16\n",
       "book_rating            float64\n",
       "rating_Avg             float64\n",
       "Book_Author             object\n",
       "Year_Of_Publication    float64\n",
       "Publisher               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b91957a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108209</th>\n",
       "      <td>101876</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.416667</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Scribner Paper Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136194</th>\n",
       "      <td>254224</td>\n",
       "      <td>37.958174</td>\n",
       "      <td>usa</td>\n",
       "      <td>246</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.708333</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Washington Square Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236874</th>\n",
       "      <td>51883</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>Mary Mcbride</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Silhouette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67363</th>\n",
       "      <td>5206</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>spain</td>\n",
       "      <td>371</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>Paulo Coelho</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Planeta Pub Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123452</th>\n",
       "      <td>257493</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>Julia Quinn</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Avon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340131</th>\n",
       "      <td>229243</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>Francesca Lia Block</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>HarperTrophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289151</th>\n",
       "      <td>98391</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>41</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Rett MacPherson</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>St. Martin's Minotaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26477</th>\n",
       "      <td>60185</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.206897</td>\n",
       "      <td>Bernhard Schlink</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Vintage Books USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322304</th>\n",
       "      <td>139579</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>287</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>Hasan Shah</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>New Directions Publishing Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257353</th>\n",
       "      <td>102647</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>261</td>\n",
       "      <td>0.9</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>Brad Meltzer</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harpercollins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        Age Country  ISBN  book_rating  rating_Avg  \\\n",
       "108209   101876  38.000000     usa     4          0.8    8.416667   \n",
       "136194   254224  37.958174     usa   246          0.8    8.708333   \n",
       "236874    51883  31.000000     usa    76          1.0   10.000000   \n",
       "67363      5206  18.000000   spain   371          0.8    7.500000   \n",
       "123452   257493  25.000000     usa   105          1.0    7.500000   \n",
       "...         ...        ...     ...   ...          ...         ...   \n",
       "340131   229243  29.000000     usa    24          0.8    8.800000   \n",
       "289151    98391  52.000000     usa    41          0.5    5.000000   \n",
       "26477     60185  46.000000     usa    89          1.0    7.206897   \n",
       "322304   139579  49.000000     usa   287          0.8    8.000000   \n",
       "257353   102647  14.000000     usa   261          0.9    7.285714   \n",
       "\n",
       "                Book_Author  Year_Of_Publication  \\\n",
       "108209  F. Scott Fitzgerald               1988.0   \n",
       "136194  William Shakespeare               1992.0   \n",
       "236874         Mary Mcbride               2002.0   \n",
       "67363          Paulo Coelho               2003.0   \n",
       "123452          Julia Quinn               2003.0   \n",
       "...                     ...                  ...   \n",
       "340131  Francesca Lia Block               1991.0   \n",
       "289151      Rett MacPherson               2004.0   \n",
       "26477      Bernhard Schlink               1999.0   \n",
       "322304           Hasan Shah               1993.0   \n",
       "257353         Brad Meltzer               1997.0   \n",
       "\n",
       "                                    Publisher  \n",
       "108209                 Scribner Paper Fiction  \n",
       "136194                Washington Square Press  \n",
       "236874                             Silhouette  \n",
       "67363                        Planeta Pub Corp  \n",
       "123452                                   Avon  \n",
       "...                                       ...  \n",
       "340131                           HarperTrophy  \n",
       "289151                  St. Martin's Minotaur  \n",
       "26477                       Vintage Books USA  \n",
       "322304  New Directions Publishing Corporation  \n",
       "257353                          Harpercollins  \n",
       "\n",
       "[384 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d48daa",
   "metadata": {},
   "source": [
    "## Training DeepFM components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32d4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(*, base, ext=\"csv\"):\n",
    "    now = datetime.datetime.utcnow()\n",
    "    return \"exp2_\" + base + \"_\" + now.strftime(\"%d%m%y_%H%M%S\") + \".\" + ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63ace163",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_names = {\n",
    "    \"dense\": [\n",
    "        \"Age\",\n",
    "        \"rating_Avg\",\n",
    "        \"Year_Of_Publication\"\n",
    "    ],\n",
    "    \"sparse\": [\n",
    "        \"Book_Author\",\n",
    "        \"Country\",\n",
    "        \"Publisher\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b860145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from modules.models import DeepFmModel\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DeepFmInputDataset:\n",
    "    data: object\n",
    "    dnn_feats: object\n",
    "    linear_feats: object\n",
    "    feat_names: object\n",
    "\n",
    "\n",
    "class DeepFMDataLoader:\n",
    "    def __init__(self, *, sparse_features, dense_features):\n",
    "        self._sparse_feats = sparse_features\n",
    "        self._dense_feats = dense_features\n",
    "        \n",
    "    def load(self, dataset):\n",
    "        nn_input = pd.DataFrame()\n",
    "        nn_input[self._sparse_feats] = dataset[self._sparse_feats]\n",
    "        nn_input[self._dense_feats] = dataset[self._dense_feats]\n",
    "        \n",
    "        for feat in self._sparse_feats:\n",
    "            encoder = LabelEncoder()\n",
    "            nn_input[feat] = encoder.fit_transform(nn_input[feat])\n",
    "            \n",
    "        mms = MinMaxScaler(feature_range=(0,1))\n",
    "        nn_input[self._dense_feats] = mms.fit_transform(nn_input[self._dense_feats])\n",
    "        \n",
    "        # problems may be here\n",
    "        sparse_feature_columns = [\n",
    "            SparseFeat(feat, vocabulary_size=nn_input[feat].nunique(), embedding_dim=4) \n",
    "            for i, feat in enumerate(self._sparse_feats)\n",
    "        ]\n",
    "\n",
    "        dense_feature_columns = [DenseFeat(feat, 1,) for feat in self._dense_feats]\n",
    "        \n",
    "        dnn_feat_cols = sparse_feature_columns + dense_feature_columns\n",
    "        linear_feat_cols = sparse_feature_columns + dense_feature_columns\n",
    "        \n",
    "        feat_names = get_feature_names(linear_feat_cols + dnn_feat_cols)\n",
    "        input_dataset = DeepFmInputDataset(\n",
    "            data=nn_input,\n",
    "            dnn_feats=dnn_feat_cols,\n",
    "            linear_feats=linear_feat_cols,\n",
    "            feat_names=feat_names\n",
    "        )\n",
    "        return input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d96f968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rating_matrix(dataset, predicted_response):\n",
    "    result = pd.DataFrame()\n",
    "    result[\"rating\"] = predicted_response.reshape((len(predicted_response),))\n",
    "    result[\"user_id\"] = dataset[\"user_id\"]\n",
    "    result[\"item_id\"] = dataset[\"item_id\"]\n",
    "    matrix = result.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45814bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_feats(feats_a, feats_b):\n",
    "    assert len(feats_a) == len(feats_b)\n",
    "    merged = []\n",
    "    for feat_a, feat_b in zip(feats_a, feats_b):\n",
    "        if isinstance(feat_a, DenseFeat):\n",
    "            continue\n",
    "        if feat_a.vocabulary_size >= feat_b.vocabulary_size:\n",
    "            merged.append(feat_a)\n",
    "        else:\n",
    "            merged.append(feat_b)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e84c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deepfm(feats, feat_names, x, y):\n",
    "    deepfm = DeepFmModel(feats, feats, feat_names)\n",
    "    train_set, test_set = train_test_split(x, test_size=0.2)\n",
    "    deepfm.train(train_set, target_values=y[:len(train_set)])\n",
    "    return deepfm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39616565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_deepfm_model(*, data_loader, train_set, test_set):\n",
    "    nn_train_input = data_loader.load(train_set)\n",
    "    nn_test_input = data_loader.load(test_set)\n",
    "    y = train_set[\"book_rating\"].values\n",
    "    \n",
    "    merged_feats = merge_feats(nn_train_input.dnn_feats, nn_test_input.dnn_feats)\n",
    "    deepfm = train_deepfm(merged_feats, nn_train_input.feat_names, x=nn_train_input.data, y=y)\n",
    "    return deepfm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a20fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset):\n",
    "    n = len(dataset)\n",
    "    mid = int(n / 2)\n",
    "    return dataset[:mid], dataset[mid:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3635e285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "DeepCTR-PyTorch version 0.2.6 detected. Your version is 0.2.5.\n",
      "Use `pip install -U deepctr-torch` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR-Torch/releases/tag/v0.2.6\n"
     ]
    }
   ],
   "source": [
    "from sdv.tabular import CTGAN, GaussianCopula, CopulaGAN\n",
    "import datetime\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def fit_syn_generator(df):\n",
    "    model = CTGAN(verbose=True, epochs=10)\n",
    "    df = df.astype(\"int64\", errors=\"ignore\") # Convert all numbers to int64\n",
    "    model.fit(df.copy())\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_worker(args):\n",
    "    dataset, name = args\n",
    "    generator = fit_syn_generator(dataset)\n",
    "    generator.save(generate_filename(base=name, ext=\"bin\"))\n",
    "    return generator\n",
    "\n",
    "\n",
    "def fit_parallel(real_dataset):\n",
    "    users = real_dataset[[\"user_id\", \"Age\", \"Country\"]].drop_duplicates().drop(\"user_id\", axis=1)\n",
    "    items = real_dataset[\n",
    "        [\"ISBN\", \"Book_Author\", \"Publisher\", \"rating_Avg\", \"Year_Of_Publication\"]\n",
    "    ].drop_duplicates().drop(\"ISBN\", axis=1)\n",
    "    print(f\"Users shape {users.shape}\")\n",
    "    print(f\"Items shape {items.shape}\")\n",
    "    args = [\n",
    "        (users, \"users_generator\"),\n",
    "        (items, \"items_generator\")\n",
    "    ]\n",
    "    with Pool() as p:\n",
    "        generators = p.map(fit_worker, args)\n",
    "    return generators\n",
    "\n",
    "\n",
    "def fit_synthetic_generators(real_dataset):\n",
    "    users = real_dataset[[\"user_id\", \"Age\", \"Country\"]].drop_duplicates().drop(\"user_id\", axis=1)\n",
    "    items = real_dataset[\n",
    "        [\"ISBN\", \"Book_Author\", \"Publisher\", \"rating_Avg\", \"Year_Of_Publication\"]\n",
    "    ].drop_duplicates().drop(\"ISBN\", axis=1)\n",
    "    \n",
    "    users_generator = fit_syn_generator(users)\n",
    "    users_generator.save(generate_filename(base=\"users_generator\", ext=\"bin\"))\n",
    "    items_generator = fit_syn_generator(items)\n",
    "    users_generator.save(generate_filename(base=\"items_generator\", ext=\"bin\"))\n",
    "    return users_generator, items_generator\n",
    "\n",
    "\n",
    "def generate_synthetic_data(users_generator, items_generator, n_users=100, n_items=100):\n",
    "    syn_users = users_generator.sample(n_users)\n",
    "    syn_items = items_generator.sample(n_items)\n",
    "    syn_users[\"user_id\"] = range(len(syn_users))\n",
    "    syn_items[\"item_id\"] = range(len(syn_items))\n",
    "    syn_users[\"_merge_key\"] = syn_items[\"_merge_key\"] = 1\n",
    "    \n",
    "    syn_dataset = pd.merge(syn_items, syn_users, on=\"_merge_key\")\n",
    "    syn_dataset = syn_dataset.drop([\"_merge_key\"], axis=1)\n",
    "    return syn_dataset\n",
    "\n",
    "\n",
    "def measure_durations(fn, dataset, n, step=5):\n",
    "    measures = []\n",
    "    for i in range(step, n, step):\n",
    "        start = datetime.datetime.utcnow()\n",
    "        fn(dataset[:i])\n",
    "        duration = datetime.datetime.utcnow() - start\n",
    "        measures.append({\"n\": i, \"time\": duration.seconds})\n",
    "        print(f\"Duration {duration.seconds}\")\n",
    "    return pd.DataFrame(measures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e958bad0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users shape (355, 2)\n",
      "Items shape (379, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  random_state=random_state).fit(X).labels_\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  2.9787,Loss D:  0.0014\n",
      "Epoch 2, Loss G:  3.0279,Loss D:  0.0044\n",
      "Epoch 3, Loss G:  2.9289,Loss D: -0.0079\n",
      "Epoch 4, Loss G:  2.9445,Loss D: -0.0136\n",
      "Epoch 1, Loss G:  5.6613,Loss D:  0.0024\n",
      "Epoch 5, Loss G:  2.9085,Loss D:  0.0032\n",
      "Epoch 6, Loss G:  2.9142,Loss D: -0.0016\n",
      "Epoch 7, Loss G:  2.9044,Loss D: -0.0246\n",
      "Epoch 8, Loss G:  2.8575,Loss D: -0.0035\n",
      "Epoch 2, Loss G:  5.6249,Loss D:  0.0024\n",
      "Epoch 9, Loss G:  2.8517,Loss D: -0.0122\n",
      "Epoch 10, Loss G:  2.8277,Loss D: -0.0223\n",
      "Epoch 3, Loss G:  5.6461,Loss D: -0.0048\n",
      "Epoch 4, Loss G:  5.6377,Loss D: -0.0203\n",
      "Epoch 5, Loss G:  5.6066,Loss D: -0.0106\n",
      "Epoch 6, Loss G:  5.6192,Loss D: -0.0051\n",
      "Epoch 7, Loss G:  5.6368,Loss D: -0.0132\n",
      "Epoch 8, Loss G:  5.6220,Loss D: -0.0294\n",
      "Epoch 9, Loss G:  5.5931,Loss D: -0.0271\n",
      "Epoch 10, Loss G:  5.6109,Loss D: -0.0290\n",
      "CPU times: user 83.8 ms, sys: 75.3 ms, total: 159 ms\n",
      "Wall time: 5.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(SEED)\n",
    "users_generator, items_generator = fit_parallel(real_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41b25fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>item_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ann Rinaldi</td>\n",
       "      <td>Little Brown &amp;amp; Company</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>usa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ann Rinaldi</td>\n",
       "      <td>Little Brown &amp;amp; Company</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>belgium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ann Rinaldi</td>\n",
       "      <td>Little Brown &amp;amp; Company</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>argentina</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ann Rinaldi</td>\n",
       "      <td>Little Brown &amp;amp; Company</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ann Rinaldi</td>\n",
       "      <td>Little Brown &amp;amp; Company</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>philippines</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Book_Author                   Publisher  rating_Avg  Year_Of_Publication  \\\n",
       "0  Ann Rinaldi  Little Brown &amp; Company           5                 2005   \n",
       "1  Ann Rinaldi  Little Brown &amp; Company           5                 2005   \n",
       "2  Ann Rinaldi  Little Brown &amp; Company           5                 2005   \n",
       "3  Ann Rinaldi  Little Brown &amp; Company           5                 2005   \n",
       "4  Ann Rinaldi  Little Brown &amp; Company           5                 2005   \n",
       "\n",
       "   item_id  Age         Country  user_id  \n",
       "0        0   38             usa        0  \n",
       "1        0   34         belgium        1  \n",
       "2        0   44       argentina        2  \n",
       "3        0   40  united kingdom        3  \n",
       "4        0   41     philippines        4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "syn_dataset = generate_synthetic_data(users_generator, items_generator)\n",
    "syn_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1d01e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating_matrices(data_loader, real_dataset, syn_dataset):\n",
    "    p1, p2 = split_dataset(real_dataset)\n",
    "    deepfm_1 = pretrain_deepfm_model(data_loader=data_loader, train_set=p1, test_set=syn_dataset)\n",
    "    deepfm_2 = pretrain_deepfm_model(data_loader=data_loader, train_set=p2, test_set=syn_dataset)\n",
    "    nn_syn_dataset = data_loader.load(syn_dataset)\n",
    "    \n",
    "    y1 = deepfm_1.predict(nn_syn_dataset.data)\n",
    "    y2 = deepfm_2.predict(nn_syn_dataset.data)\n",
    "    \n",
    "    matrix_1 = to_rating_matrix(syn_dataset, y1)\n",
    "    matrix_2 = to_rating_matrix(syn_dataset, y2)\n",
    "    return matrix_1, matrix_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "656a4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DeepFMDataLoader(sparse_features=attributes_names[\"sparse\"], dense_features=attributes_names[\"dense\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89b23468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 122 samples, validate on 31 samples, 1 steps per epoch\n",
      "Epoch 1/10\n",
      "0s - loss:  0.6198 - mse:  0.6198 - val_mse:  0.5638\n",
      "Epoch 2/10\n",
      "0s - loss:  0.5433 - mse:  0.5433 - val_mse:  0.5020\n",
      "Epoch 3/10\n",
      "0s - loss:  0.4814 - mse:  0.4814 - val_mse:  0.4557\n",
      "Epoch 4/10\n",
      "0s - loss:  0.4347 - mse:  0.4347 - val_mse:  0.4154\n",
      "Epoch 5/10\n",
      "0s - loss:  0.3942 - mse:  0.3942 - val_mse:  0.3755\n",
      "Epoch 6/10\n",
      "0s - loss:  0.3543 - mse:  0.3543 - val_mse:  0.3361\n",
      "Epoch 7/10\n",
      "0s - loss:  0.3152 - mse:  0.3152 - val_mse:  0.2974\n",
      "Epoch 8/10\n",
      "0s - loss:  0.2770 - mse:  0.2770 - val_mse:  0.2598\n",
      "Epoch 9/10\n",
      "0s - loss:  0.2402 - mse:  0.2402 - val_mse:  0.2237\n",
      "Epoch 10/10\n",
      "0s - loss:  0.2051 - mse:  0.2051 - val_mse:  0.1894\n",
      "cpu\n",
      "Train on 122 samples, validate on 31 samples, 1 steps per epoch\n",
      "Epoch 1/10\n",
      "0s - loss:  0.5662 - mse:  0.5662 - val_mse:  0.6441\n",
      "Epoch 2/10\n",
      "0s - loss:  0.4983 - mse:  0.4983 - val_mse:  0.5802\n",
      "Epoch 3/10\n",
      "0s - loss:  0.4409 - mse:  0.4409 - val_mse:  0.5295\n",
      "Epoch 4/10\n",
      "0s - loss:  0.3955 - mse:  0.3955 - val_mse:  0.4860\n",
      "Epoch 5/10\n",
      "0s - loss:  0.3568 - mse:  0.3568 - val_mse:  0.4434\n",
      "Epoch 6/10\n",
      "0s - loss:  0.3193 - mse:  0.3193 - val_mse:  0.4011\n",
      "Epoch 7/10\n",
      "0s - loss:  0.2828 - mse:  0.2828 - val_mse:  0.3594\n",
      "Epoch 8/10\n",
      "0s - loss:  0.2473 - mse:  0.2473 - val_mse:  0.3186\n",
      "Epoch 9/10\n",
      "0s - loss:  0.2134 - mse:  0.2134 - val_mse:  0.2792\n",
      "Epoch 10/10\n",
      "0s - loss:  0.1813 - mse:  0.1813 - val_mse:  0.2414\n",
      "CPU times: user 660 ms, sys: 46.2 ms, total: 707 ms\n",
      "Wall time: 779 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(SEED)\n",
    "matrix_1, matrix_2 = calculate_rating_matrices(data_loader, real_dataset, syn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5f811bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.378651</td>\n",
       "      <td>0.368736</td>\n",
       "      <td>0.377377</td>\n",
       "      <td>0.367857</td>\n",
       "      <td>0.368551</td>\n",
       "      <td>0.368349</td>\n",
       "      <td>0.378979</td>\n",
       "      <td>0.378373</td>\n",
       "      <td>0.378024</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368541</td>\n",
       "      <td>0.379108</td>\n",
       "      <td>0.368619</td>\n",
       "      <td>0.377718</td>\n",
       "      <td>0.376881</td>\n",
       "      <td>0.368327</td>\n",
       "      <td>0.368393</td>\n",
       "      <td>0.378881</td>\n",
       "      <td>0.378124</td>\n",
       "      <td>0.378821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.388960</td>\n",
       "      <td>0.378957</td>\n",
       "      <td>0.387741</td>\n",
       "      <td>0.377837</td>\n",
       "      <td>0.378760</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.389444</td>\n",
       "      <td>0.388602</td>\n",
       "      <td>0.387997</td>\n",
       "      <td>0.368395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.389623</td>\n",
       "      <td>0.378875</td>\n",
       "      <td>0.387769</td>\n",
       "      <td>0.386825</td>\n",
       "      <td>0.378439</td>\n",
       "      <td>0.378477</td>\n",
       "      <td>0.389337</td>\n",
       "      <td>0.388411</td>\n",
       "      <td>0.389290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388645</td>\n",
       "      <td>0.378901</td>\n",
       "      <td>0.387604</td>\n",
       "      <td>0.377967</td>\n",
       "      <td>0.378744</td>\n",
       "      <td>0.378442</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.388596</td>\n",
       "      <td>0.388269</td>\n",
       "      <td>0.368384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378631</td>\n",
       "      <td>0.389435</td>\n",
       "      <td>0.378724</td>\n",
       "      <td>0.387722</td>\n",
       "      <td>0.386964</td>\n",
       "      <td>0.378259</td>\n",
       "      <td>0.378524</td>\n",
       "      <td>0.389185</td>\n",
       "      <td>0.388458</td>\n",
       "      <td>0.389144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.378643</td>\n",
       "      <td>0.368729</td>\n",
       "      <td>0.377369</td>\n",
       "      <td>0.367850</td>\n",
       "      <td>0.368543</td>\n",
       "      <td>0.368341</td>\n",
       "      <td>0.378971</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>0.378016</td>\n",
       "      <td>0.358341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368534</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.368612</td>\n",
       "      <td>0.377710</td>\n",
       "      <td>0.376874</td>\n",
       "      <td>0.368320</td>\n",
       "      <td>0.368386</td>\n",
       "      <td>0.378873</td>\n",
       "      <td>0.378116</td>\n",
       "      <td>0.378814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.388696</td>\n",
       "      <td>0.378483</td>\n",
       "      <td>0.387018</td>\n",
       "      <td>0.377579</td>\n",
       "      <td>0.378288</td>\n",
       "      <td>0.378154</td>\n",
       "      <td>0.388775</td>\n",
       "      <td>0.388205</td>\n",
       "      <td>0.387798</td>\n",
       "      <td>0.368111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378331</td>\n",
       "      <td>0.388821</td>\n",
       "      <td>0.378417</td>\n",
       "      <td>0.387777</td>\n",
       "      <td>0.386850</td>\n",
       "      <td>0.378329</td>\n",
       "      <td>0.378176</td>\n",
       "      <td>0.388638</td>\n",
       "      <td>0.387840</td>\n",
       "      <td>0.388561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.378686</td>\n",
       "      <td>0.368771</td>\n",
       "      <td>0.377411</td>\n",
       "      <td>0.367891</td>\n",
       "      <td>0.368585</td>\n",
       "      <td>0.368383</td>\n",
       "      <td>0.379013</td>\n",
       "      <td>0.378407</td>\n",
       "      <td>0.378056</td>\n",
       "      <td>0.358382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368576</td>\n",
       "      <td>0.379142</td>\n",
       "      <td>0.368654</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.376915</td>\n",
       "      <td>0.368362</td>\n",
       "      <td>0.368427</td>\n",
       "      <td>0.378916</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.378856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.378651</td>\n",
       "      <td>0.368736</td>\n",
       "      <td>0.377377</td>\n",
       "      <td>0.367857</td>\n",
       "      <td>0.368551</td>\n",
       "      <td>0.368349</td>\n",
       "      <td>0.378979</td>\n",
       "      <td>0.378373</td>\n",
       "      <td>0.378024</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368541</td>\n",
       "      <td>0.379108</td>\n",
       "      <td>0.368619</td>\n",
       "      <td>0.377718</td>\n",
       "      <td>0.376881</td>\n",
       "      <td>0.368327</td>\n",
       "      <td>0.368393</td>\n",
       "      <td>0.378881</td>\n",
       "      <td>0.378124</td>\n",
       "      <td>0.378821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.388604</td>\n",
       "      <td>0.378771</td>\n",
       "      <td>0.387605</td>\n",
       "      <td>0.377688</td>\n",
       "      <td>0.378546</td>\n",
       "      <td>0.378408</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>0.388240</td>\n",
       "      <td>0.387640</td>\n",
       "      <td>0.368298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378615</td>\n",
       "      <td>0.389335</td>\n",
       "      <td>0.378686</td>\n",
       "      <td>0.387360</td>\n",
       "      <td>0.386430</td>\n",
       "      <td>0.378178</td>\n",
       "      <td>0.378253</td>\n",
       "      <td>0.389013</td>\n",
       "      <td>0.388080</td>\n",
       "      <td>0.388978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.388720</td>\n",
       "      <td>0.378907</td>\n",
       "      <td>0.387651</td>\n",
       "      <td>0.377939</td>\n",
       "      <td>0.378752</td>\n",
       "      <td>0.378481</td>\n",
       "      <td>0.389243</td>\n",
       "      <td>0.388625</td>\n",
       "      <td>0.388241</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378668</td>\n",
       "      <td>0.389500</td>\n",
       "      <td>0.378757</td>\n",
       "      <td>0.387736</td>\n",
       "      <td>0.386938</td>\n",
       "      <td>0.378287</td>\n",
       "      <td>0.378519</td>\n",
       "      <td>0.389245</td>\n",
       "      <td>0.388478</td>\n",
       "      <td>0.389194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.378672</td>\n",
       "      <td>0.368756</td>\n",
       "      <td>0.377396</td>\n",
       "      <td>0.367878</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.368369</td>\n",
       "      <td>0.378999</td>\n",
       "      <td>0.378393</td>\n",
       "      <td>0.378044</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368561</td>\n",
       "      <td>0.379127</td>\n",
       "      <td>0.368640</td>\n",
       "      <td>0.377739</td>\n",
       "      <td>0.376902</td>\n",
       "      <td>0.368348</td>\n",
       "      <td>0.368414</td>\n",
       "      <td>0.378901</td>\n",
       "      <td>0.378144</td>\n",
       "      <td>0.378841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id        0         1         2         3         4         5         6   \\\n",
       "user_id                                                                         \n",
       "0        0.378651  0.368736  0.377377  0.367857  0.368551  0.368349  0.378979   \n",
       "1        0.388960  0.378957  0.387741  0.377837  0.378760  0.378600  0.389444   \n",
       "2        0.388645  0.378901  0.387604  0.377967  0.378744  0.378442  0.389152   \n",
       "3        0.378643  0.368729  0.377369  0.367850  0.368543  0.368341  0.378971   \n",
       "4        0.388696  0.378483  0.387018  0.377579  0.378288  0.378154  0.388775   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "95       0.378686  0.368771  0.377411  0.367891  0.368585  0.368383  0.379013   \n",
       "96       0.378651  0.368736  0.377377  0.367857  0.368551  0.368349  0.378979   \n",
       "97       0.388604  0.378771  0.387605  0.377688  0.378546  0.378408  0.389193   \n",
       "98       0.388720  0.378907  0.387651  0.377939  0.378752  0.378481  0.389243   \n",
       "99       0.378672  0.368756  0.377396  0.367878  0.368571  0.368369  0.378999   \n",
       "\n",
       "item_id        7         8         9   ...        90        91        92  \\\n",
       "user_id                                ...                                 \n",
       "0        0.378373  0.378024  0.358348  ...  0.368541  0.379108  0.368619   \n",
       "1        0.388602  0.387997  0.368395  ...  0.378788  0.389623  0.378875   \n",
       "2        0.388596  0.388269  0.368384  ...  0.378631  0.389435  0.378724   \n",
       "3        0.378365  0.378016  0.358341  ...  0.368534  0.379100  0.368612   \n",
       "4        0.388205  0.387798  0.368111  ...  0.378331  0.388821  0.378417   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "95       0.378407  0.378056  0.358382  ...  0.368576  0.379142  0.368654   \n",
       "96       0.378373  0.378024  0.358348  ...  0.368541  0.379108  0.368619   \n",
       "97       0.388240  0.387640  0.368298  ...  0.378615  0.389335  0.378686   \n",
       "98       0.388625  0.388241  0.368366  ...  0.378668  0.389500  0.378757   \n",
       "99       0.378393  0.378044  0.358368  ...  0.368561  0.379127  0.368640   \n",
       "\n",
       "item_id        93        94        95        96        97        98        99  \n",
       "user_id                                                                        \n",
       "0        0.377718  0.376881  0.368327  0.368393  0.378881  0.378124  0.378821  \n",
       "1        0.387769  0.386825  0.378439  0.378477  0.389337  0.388411  0.389290  \n",
       "2        0.387722  0.386964  0.378259  0.378524  0.389185  0.388458  0.389144  \n",
       "3        0.377710  0.376874  0.368320  0.368386  0.378873  0.378116  0.378814  \n",
       "4        0.387777  0.386850  0.378329  0.378176  0.388638  0.387840  0.388561  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "95       0.377752  0.376915  0.368362  0.368427  0.378916  0.378158  0.378856  \n",
       "96       0.377718  0.376881  0.368327  0.368393  0.378881  0.378124  0.378821  \n",
       "97       0.387360  0.386430  0.378178  0.378253  0.389013  0.388080  0.388978  \n",
       "98       0.387736  0.386938  0.378287  0.378519  0.389245  0.388478  0.389194  \n",
       "99       0.377739  0.376902  0.368348  0.368414  0.378901  0.378144  0.378841  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-blade",
   "metadata": {},
   "source": [
    "## Create response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee71b986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modules.trainers' from '/Users/vldpro/Workspace/university/recsys/modules/trainers.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from modules import models, evaluator, trainers, utils\n",
    "importlib.reload(models)\n",
    "importlib.reload(evaluator)\n",
    "importlib.reload(trainers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c73a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFunction:\n",
    "    def __init__(self, deepfm_matrix_1, deepfm_matrix_2):\n",
    "        assert deepfm_matrix_1.shape == deepfm_matrix_2.shape\n",
    "        self._deepfm_matrix_1 = deepfm_matrix_1\n",
    "        self._deepfm_matrix_2 = deepfm_matrix_2\n",
    "        \n",
    "    def __call__(self, a1: float, a2: float):\n",
    "        a3 = max(0.0, 1 - a1 - a2)\n",
    "        return (\n",
    "            a1 * self._deepfm_matrix_1\n",
    "            + a2 * self._deepfm_matrix_2\n",
    "            + a3 * npr.normal(0, 1, size=self._deepfm_matrix_1.shape)\n",
    "        )\n",
    "    \n",
    "\n",
    "resp_function = evaluator.ResponseFunctionConfig(\n",
    "    factory=ResponseFunction, args=[matrix_1, matrix_2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b9702",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "348237df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.Subprocess started.Subprocess started.\n",
      "\n",
      "\n",
      "Load data finished. Number of users:Load data finished. Number of users:Load data finished. Number of users:   100100100   Number of items:Number of items:Number of items:   100100100\n",
      "\n",
      "\n",
      "IAutoRec.IAutoRec."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_evaluators = [\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.AutoRecTrainTestExecutor,\n",
    "        args={\"config\": {\"epoch\": 50}},\n",
    "        model_name=\"autorec\"\n",
    "    ),\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.SvdTrainTestExecutor,\n",
    "        args={},\n",
    "        model_name=\"svd\"\n",
    "    ),\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.KnnTrainTestExecutor,\n",
    "        args={},\n",
    "        model_name=\"knn\"\n",
    "    )\n",
    "]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "_evaluator = evaluator.Evaluator(resp_function, n_proc=4)\n",
    "_res = _evaluator.evaluate(\n",
    "    _evaluators, \n",
    "    a_sample_rate=3,\n",
    "    test_size=0.1,\n",
    "    sample_sizes=[0.1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4755a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63ba90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res.to_csv(generate_filename(base=\"evalution_result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-dialogue",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52b397d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_surface = utils.group_points_by_minimum_error(_res)\n",
    "error_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27702434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from modules import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "for ss in [0.1]:\n",
    "    fig = px.scatter_3d(\n",
    "        error_surface[error_surface[\"sample_size\"] == ss], \n",
    "        x='a1', \n",
    "        y='a2', \n",
    "        z='rmse',\n",
    "        size=\"rmse\",\n",
    "        size_max=18, \n",
    "        opacity=1,\n",
    "        color=\"model_name\",\n",
    "        color_continuous_scale=px.colors.sequential.thermal[::-1]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "    )\n",
    "\n",
    "    fig.show(\"notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "fb17c3c70aa2daba89de097746222c240ddefaef361ffa09e744913d93ac8208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
