{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "mysterious-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import random as npr\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a3ed26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "BOOKS_DATASET_PATH = \"books_dataset_cleaned.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-yugoslavia",
   "metadata": {},
   "source": [
    "## Load and transform restaurants data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3adefce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>rating_sum</th>\n",
       "      <th>Count_All_Rate</th>\n",
       "      <th>Book_Title</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334121</th>\n",
       "      <td>160643</td>\n",
       "      <td>22.0</td>\n",
       "      <td>france</td>\n",
       "      <td>2266065998</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>L'Empire dÃ?Â©barque</td>\n",
       "      <td>Marion Zimmer Bradley</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115510</th>\n",
       "      <td>174601</td>\n",
       "      <td>37.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>0505525178</td>\n",
       "      <td>3</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>Improper English</td>\n",
       "      <td>Katie Macalister</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Love Spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191683</th>\n",
       "      <td>113259</td>\n",
       "      <td>30.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>0446611913</td>\n",
       "      <td>10</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>240</td>\n",
       "      <td>67</td>\n",
       "      <td>Up Country</td>\n",
       "      <td>Nelson DeMille</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Warner Vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151192</th>\n",
       "      <td>171904</td>\n",
       "      <td>28.0</td>\n",
       "      <td>spain</td>\n",
       "      <td>0739307320</td>\n",
       "      <td>8</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>The Devil Wears Prada</td>\n",
       "      <td>LAUREN WEISBERGER</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Random House Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173793</th>\n",
       "      <td>30711</td>\n",
       "      <td>32.0</td>\n",
       "      <td>australia</td>\n",
       "      <td>0064472051</td>\n",
       "      <td>7</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>The Hounds of the Morrigan</td>\n",
       "      <td>Pat O'Shea</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>HarperTrophy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id   Age    Country        ISBN  book_rating  rating_Avg  \\\n",
       "334121   160643  22.0     france  2266065998            5    5.000000   \n",
       "115510   174601  37.0        usa  0505525178            3    7.300000   \n",
       "191683   113259  30.0        usa  0446611913           10    8.000000   \n",
       "151192   171904  28.0      spain  0739307320            8    7.666667   \n",
       "173793    30711  32.0  australia  0064472051            7    8.166667   \n",
       "\n",
       "        rating_sum  Count_All_Rate                  Book_Title  \\\n",
       "334121           5               4        L'Empire dÃ?Â©barque   \n",
       "115510          73              22            Improper English   \n",
       "191683         240              67                  Up Country   \n",
       "151192          23               5       The Devil Wears Prada   \n",
       "173793          49              13  The Hounds of the Morrigan   \n",
       "\n",
       "                  Book_Author  Year_Of_Publication           Publisher  \n",
       "334121  Marion Zimmer Bradley               1999.0              Pocket  \n",
       "115510       Katie Macalister               2003.0          Love Spell  \n",
       "191683         Nelson DeMille               2003.0       Warner Vision  \n",
       "151192      LAUREN WEISBERGER               2003.0  Random House Audio  \n",
       "173793             Pat O'Shea               1999.0        HarperTrophy  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset = pd.read_csv(BOOKS_DATASET_PATH)\n",
    "real_dataset = real_dataset.drop([\"Location\"], axis=1)\n",
    "real_dataset = real_dataset.sample(int(len(real_dataset) * 0.001))\n",
    "real_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d52f367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset[\"ISBN\"] = real_dataset[\"ISBN\"].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cd4c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset[\"book_rating\"] = real_dataset[\"book_rating\"] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9a105d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                  int64\n",
       "Age                    float64\n",
       "Country                 object\n",
       "ISBN                     int16\n",
       "book_rating            float64\n",
       "rating_Avg             float64\n",
       "rating_sum               int64\n",
       "Count_All_Rate           int64\n",
       "Book_Title              object\n",
       "Book_Author             object\n",
       "Year_Of_Publication    float64\n",
       "Publisher               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b91957a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>rating_sum</th>\n",
       "      <th>Count_All_Rate</th>\n",
       "      <th>Book_Title</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334121</th>\n",
       "      <td>160643</td>\n",
       "      <td>22.0</td>\n",
       "      <td>france</td>\n",
       "      <td>356</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>L'Empire dÃ?Â©barque</td>\n",
       "      <td>Marion Zimmer Bradley</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115510</th>\n",
       "      <td>174601</td>\n",
       "      <td>37.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>198</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>Improper English</td>\n",
       "      <td>Katie Macalister</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Love Spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191683</th>\n",
       "      <td>113259</td>\n",
       "      <td>30.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>240</td>\n",
       "      <td>67</td>\n",
       "      <td>Up Country</td>\n",
       "      <td>Nelson DeMille</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Warner Vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151192</th>\n",
       "      <td>171904</td>\n",
       "      <td>28.0</td>\n",
       "      <td>spain</td>\n",
       "      <td>270</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>The Devil Wears Prada</td>\n",
       "      <td>LAUREN WEISBERGER</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Random House Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173793</th>\n",
       "      <td>30711</td>\n",
       "      <td>32.0</td>\n",
       "      <td>australia</td>\n",
       "      <td>21</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>The Hounds of the Morrigan</td>\n",
       "      <td>Pat O'Shea</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>HarperTrophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249110</th>\n",
       "      <td>60244</td>\n",
       "      <td>47.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>126</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>The Shelter of Each Other: Rebuilding Our Fami...</td>\n",
       "      <td>Mary Bray Pipher</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77793</th>\n",
       "      <td>83363</td>\n",
       "      <td>34.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.909091</td>\n",
       "      <td>174</td>\n",
       "      <td>47</td>\n",
       "      <td>The Pearl</td>\n",
       "      <td>John Steinbeck</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Penguin USA (Paper)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36868</th>\n",
       "      <td>186784</td>\n",
       "      <td>17.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>146</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.033981</td>\n",
       "      <td>1861</td>\n",
       "      <td>334</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Boo...</td>\n",
       "      <td>J. K. Rowling</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259705</th>\n",
       "      <td>98391</td>\n",
       "      <td>52.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>199</td>\n",
       "      <td>0.9</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>Love Bites</td>\n",
       "      <td>Lynsay Sands</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Love Spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280164</th>\n",
       "      <td>89207</td>\n",
       "      <td>26.0</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>25</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>Over to You: Ten Stories of Flyers and Flying</td>\n",
       "      <td>Roald Dahl</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id   Age         Country  ISBN  book_rating  rating_Avg  \\\n",
       "334121   160643  22.0          france   356          0.5    5.000000   \n",
       "115510   174601  37.0             usa   198          0.3    7.300000   \n",
       "191683   113259  30.0             usa   173          1.0    8.000000   \n",
       "151192   171904  28.0           spain   270          0.8    7.666667   \n",
       "173793    30711  32.0       australia    21          0.7    8.166667   \n",
       "...         ...   ...             ...   ...          ...         ...   \n",
       "249110    60244  47.0             usa   126          0.9    9.000000   \n",
       "77793     83363  34.0             usa    28          1.0    7.909091   \n",
       "36868    186784  17.0             usa   146          0.9    9.033981   \n",
       "259705    98391  52.0             usa   199          0.9    7.500000   \n",
       "280164    89207  26.0  united kingdom    25          0.8    8.666667   \n",
       "\n",
       "        rating_sum  Count_All_Rate  \\\n",
       "334121           5               4   \n",
       "115510          73              22   \n",
       "191683         240              67   \n",
       "151192          23               5   \n",
       "173793          49              13   \n",
       "...            ...             ...   \n",
       "249110           9               5   \n",
       "77793          174              47   \n",
       "36868         1861             334   \n",
       "259705          60              25   \n",
       "280164          26               6   \n",
       "\n",
       "                                               Book_Title  \\\n",
       "334121                               L'Empire dÃ?Â©barque   \n",
       "115510                                   Improper English   \n",
       "191683                                         Up Country   \n",
       "151192                              The Devil Wears Prada   \n",
       "173793                         The Hounds of the Morrigan   \n",
       "...                                                   ...   \n",
       "249110  The Shelter of Each Other: Rebuilding Our Fami...   \n",
       "77793                                           The Pearl   \n",
       "36868   Harry Potter and the Order of the Phoenix (Boo...   \n",
       "259705                                         Love Bites   \n",
       "280164      Over to You: Ten Stories of Flyers and Flying   \n",
       "\n",
       "                  Book_Author  Year_Of_Publication                Publisher  \n",
       "334121  Marion Zimmer Bradley               1999.0                   Pocket  \n",
       "115510       Katie Macalister               2003.0               Love Spell  \n",
       "191683         Nelson DeMille               2003.0            Warner Vision  \n",
       "151192      LAUREN WEISBERGER               2003.0       Random House Audio  \n",
       "173793             Pat O'Shea               1999.0             HarperTrophy  \n",
       "...                       ...                  ...                      ...  \n",
       "249110       Mary Bray Pipher               1996.0  Putnam Publishing Group  \n",
       "77793          John Steinbeck               2000.0      Penguin USA (Paper)  \n",
       "36868           J. K. Rowling               2003.0               Scholastic  \n",
       "259705           Lynsay Sands               2004.0               Love Spell  \n",
       "280164             Roald Dahl               1989.0            Penguin Books  \n",
       "\n",
       "[383 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d48daa",
   "metadata": {},
   "source": [
    "## Training DeepFM components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e32d4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(*, base, ext=\"csv\"):\n",
    "    now = datetime.datetime.utcnow()\n",
    "    return \"exp2_\" + base + \"_\" + now.strftime(\"%d%m%y_%H%M%S\") + \".\" + ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63ace163",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_names = {\n",
    "    \"dense\": [\n",
    "        \"Age\",\n",
    "        \"rating_Avg\",\n",
    "        \"rating_sum\",\n",
    "        \"Count_All_Rate\",\n",
    "        \"Year_Of_Publication\"\n",
    "    ],\n",
    "    \"sparse\": [\n",
    "        \"Book_Title\",\n",
    "        \"Book_Author\",\n",
    "        \"Country\",\n",
    "        \"Publisher\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b860145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from modules.models import DeepFmModel\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DeepFmInputDataset:\n",
    "    data: object\n",
    "    dnn_feats: object\n",
    "    linear_feats: object\n",
    "    feat_names: object\n",
    "\n",
    "\n",
    "class DeepFMDataLoader:\n",
    "    def __init__(self, *, sparse_features, dense_features):\n",
    "        self._sparse_feats = sparse_features\n",
    "        self._dense_feats = dense_features\n",
    "        \n",
    "    def load(self, dataset):\n",
    "        nn_input = pd.DataFrame()\n",
    "        nn_input[self._sparse_feats] = dataset[self._sparse_feats]\n",
    "        nn_input[self._dense_feats] = dataset[self._dense_feats]\n",
    "        \n",
    "        for feat in self._sparse_feats:\n",
    "            encoder = LabelEncoder()\n",
    "            nn_input[feat] = encoder.fit_transform(nn_input[feat])\n",
    "            \n",
    "        mms = MinMaxScaler(feature_range=(0,1))\n",
    "        nn_input[self._dense_feats] = mms.fit_transform(nn_input[self._dense_feats])\n",
    "        \n",
    "        # problems may be here\n",
    "        sparse_feature_columns = [\n",
    "            SparseFeat(feat, vocabulary_size=nn_input[feat].nunique(), embedding_dim=4) \n",
    "            for i, feat in enumerate(self._sparse_feats)\n",
    "        ]\n",
    "\n",
    "        dense_feature_columns = [DenseFeat(feat, 1,) for feat in self._dense_feats]\n",
    "        \n",
    "        dnn_feat_cols = sparse_feature_columns + dense_feature_columns\n",
    "        linear_feat_cols = sparse_feature_columns + dense_feature_columns\n",
    "        \n",
    "        feat_names = get_feature_names(linear_feat_cols + dnn_feat_cols)\n",
    "        input_dataset = DeepFmInputDataset(\n",
    "            data=nn_input,\n",
    "            dnn_feats=dnn_feat_cols,\n",
    "            linear_feats=linear_feat_cols,\n",
    "            feat_names=feat_names\n",
    "        )\n",
    "        return input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d96f968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rating_matrix(dataset, predicted_response):\n",
    "    result = pd.DataFrame()\n",
    "    result[\"rating\"] = predicted_response.reshape((len(predicted_response),))\n",
    "    result[\"user_id\"] = dataset[\"user_id\"]\n",
    "    result[\"item_id\"] = dataset[\"item_id\"]\n",
    "    matrix = result.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45814bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_feats(feats_a, feats_b):\n",
    "    assert len(feats_a) == len(feats_b)\n",
    "    merged = []\n",
    "    for feat_a, feat_b in zip(feats_a, feats_b):\n",
    "        if isinstance(feat_a, DenseFeat):\n",
    "            continue\n",
    "        if feat_a.vocabulary_size >= feat_b.vocabulary_size:\n",
    "            merged.append(feat_a)\n",
    "        else:\n",
    "            merged.append(feat_b)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67e84c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deepfm(feats, feat_names, x, y):\n",
    "    deepfm = DeepFmModel(feats, feats, feat_names)\n",
    "    train_set, test_set = train_test_split(x, test_size=0.2)\n",
    "    deepfm.train(train_set, target_values=y[:len(train_set)])\n",
    "    return deepfm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39616565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_deepfm_model(*, data_loader, train_set, test_set):\n",
    "    nn_train_input = data_loader.load(train_set)\n",
    "    nn_test_input = data_loader.load(test_set)\n",
    "    y = train_set[\"book_rating\"].values\n",
    "    \n",
    "    merged_feats = merge_feats(nn_train_input.dnn_feats, nn_test_input.dnn_feats)\n",
    "    deepfm = train_deepfm(merged_feats, nn_train_input.feat_names, x=nn_train_input.data, y=y)\n",
    "    return deepfm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9a20fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset):\n",
    "    n = len(dataset)\n",
    "    mid = int(n / 2)\n",
    "    return dataset[:mid], dataset[mid:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3635e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.tabular import CTGAN\n",
    "import datetime\n",
    "\n",
    "\n",
    "def fit_syn_generator(df):\n",
    "    model = CTGAN()\n",
    "    df = df.astype(\"int64\", errors=\"ignore\") # Convert all numbers to int64\n",
    "    model.fit(df.copy())\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_synthetic_generators(real_dataset):\n",
    "    users = real_dataset[[\"user_id\", \"Age\", \"Country\"]].drop_duplicates().drop(\"user_id\", axis=1)\n",
    "    items = real_dataset[\n",
    "        [\"ISBN\", \"Book_Title\", \"Book_Author\", \"Publisher\", \"rating_Avg\", \"rating_sum\", \"Count_All_Rate\", \"Year_Of_Publication\"]\n",
    "    ].drop_duplicates().drop(\"ISBN\", axis=1)\n",
    "    \n",
    "    users_generator = fit_syn_generator(users)\n",
    "    users_generator.save(generate_filename(base=\"users_generator\", ext=\"bin\"))\n",
    "    items_generator = fit_syn_generator(items)\n",
    "    users_generator.save(generate_filename(base=\"items_generator\", ext=\"bin\"))\n",
    "    return users_generator, items_generator\n",
    "\n",
    "\n",
    "def generate_synthetic_data(users_generator, items_generator, n_users=100, n_items=100):\n",
    "    syn_users = users_generator.sample(n_users)\n",
    "    syn_items = items_generator.sample(n_items)\n",
    "    syn_users[\"user_id\"] = range(len(syn_users))\n",
    "    syn_items[\"item_id\"] = range(len(syn_items))\n",
    "    syn_users[\"_merge_key\"] = syn_items[\"_merge_key\"] = 1\n",
    "    \n",
    "    syn_dataset = pd.merge(syn_items, syn_users, on=\"_merge_key\")\n",
    "    syn_dataset = syn_dataset.drop([\"_merge_key\"], axis=1)\n",
    "    return syn_dataset\n",
    "\n",
    "\n",
    "def measure_durations(fn, dataset, n, step=5):\n",
    "    measures = []\n",
    "    for i in range(step, n, step):\n",
    "        start = datetime.datetime.utcnow()\n",
    "        fn(dataset[:i])\n",
    "        duration = datetime.datetime.utcnow() - start\n",
    "        measures.append({\"n\": i, \"time\": duration.seconds})\n",
    "        print(f\"Duration {duration.seconds}\")\n",
    "    return pd.DataFrame(measures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e958bad0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  random_state=random_state).fit(X).labels_\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 41s, sys: 50.2 s, total: 4min 32s\n",
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(SEED)\n",
    "users_generator, items_generator = fit_synthetic_generators(real_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41b25fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Title</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>rating_sum</th>\n",
       "      <th>Count_All_Rate</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>item_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Protein Power Lifeplan</td>\n",
       "      <td>Jack Kerouac</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>4</td>\n",
       "      <td>-37</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>sweden</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Protein Power Lifeplan</td>\n",
       "      <td>Jack Kerouac</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>4</td>\n",
       "      <td>-37</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>switzerland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Protein Power Lifeplan</td>\n",
       "      <td>Jack Kerouac</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>4</td>\n",
       "      <td>-37</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>germany</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Protein Power Lifeplan</td>\n",
       "      <td>Jack Kerouac</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>4</td>\n",
       "      <td>-37</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>italy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Protein Power Lifeplan</td>\n",
       "      <td>Jack Kerouac</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>4</td>\n",
       "      <td>-37</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>canada</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Book_Title   Book_Author           Publisher  rating_Avg  \\\n",
       "0  The Protein Power Lifeplan  Jack Kerouac  Dover Publications           4   \n",
       "1  The Protein Power Lifeplan  Jack Kerouac  Dover Publications           4   \n",
       "2  The Protein Power Lifeplan  Jack Kerouac  Dover Publications           4   \n",
       "3  The Protein Power Lifeplan  Jack Kerouac  Dover Publications           4   \n",
       "4  The Protein Power Lifeplan  Jack Kerouac  Dover Publications           4   \n",
       "\n",
       "   rating_sum  Count_All_Rate  Year_Of_Publication  item_id  Age      Country  \\\n",
       "0         -37               2                 2000        0   37       sweden   \n",
       "1         -37               2                 2000        0   48  switzerland   \n",
       "2         -37               2                 2000        0   38      germany   \n",
       "3         -37               2                 2000        0   39        italy   \n",
       "4         -37               2                 2000        0   39       canada   \n",
       "\n",
       "   user_id  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        4  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "syn_dataset = generate_synthetic_data(users_generator, items_generator)\n",
    "syn_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1d01e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating_matrices(data_loader, real_dataset, syn_dataset):\n",
    "    p1, p2 = split_dataset(real_dataset)\n",
    "    deepfm_1 = pretrain_deepfm_model(data_loader=data_loader, train_set=p1, test_set=syn_dataset)\n",
    "    deepfm_2 = pretrain_deepfm_model(data_loader=data_loader, train_set=p2, test_set=syn_dataset)\n",
    "    nn_syn_dataset = data_loader.load(syn_dataset)\n",
    "    \n",
    "    y1 = deepfm_1.predict(nn_syn_dataset.data)\n",
    "    y2 = deepfm_2.predict(nn_syn_dataset.data)\n",
    "    \n",
    "    matrix_1 = to_rating_matrix(syn_dataset, y1)\n",
    "    matrix_2 = to_rating_matrix(syn_dataset, y2)\n",
    "    return matrix_1, matrix_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "656a4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DeepFMDataLoader(sparse_features=attributes_names[\"sparse\"], dense_features=attributes_names[\"dense\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89b23468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 121 samples, validate on 31 samples, 1 steps per epoch\n",
      "Epoch 1/10\n",
      "0s - loss:  0.6530 - mse:  0.6530 - val_mse:  0.5470\n",
      "Epoch 2/10\n",
      "0s - loss:  0.5729 - mse:  0.5729 - val_mse:  0.4870\n",
      "Epoch 3/10\n",
      "0s - loss:  0.5080 - mse:  0.5080 - val_mse:  0.4402\n",
      "Epoch 4/10\n",
      "0s - loss:  0.4570 - mse:  0.4570 - val_mse:  0.4046\n",
      "Epoch 5/10\n",
      "0s - loss:  0.4177 - mse:  0.4177 - val_mse:  0.3713\n",
      "Epoch 6/10\n",
      "0s - loss:  0.3809 - mse:  0.3809 - val_mse:  0.3378\n",
      "Epoch 7/10\n",
      "0s - loss:  0.3441 - mse:  0.3441 - val_mse:  0.3043\n",
      "Epoch 8/10\n",
      "0s - loss:  0.3077 - mse:  0.3077 - val_mse:  0.2711\n",
      "Epoch 9/10\n",
      "0s - loss:  0.2719 - mse:  0.2719 - val_mse:  0.2385\n",
      "Epoch 10/10\n",
      "0s - loss:  0.2370 - mse:  0.2370 - val_mse:  0.2068\n",
      "cpu\n",
      "Train on 122 samples, validate on 31 samples, 1 steps per epoch\n",
      "Epoch 1/10\n",
      "0s - loss:  0.5708 - mse:  0.5708 - val_mse:  0.5696\n",
      "Epoch 2/10\n",
      "0s - loss:  0.4842 - mse:  0.4842 - val_mse:  0.4950\n",
      "Epoch 3/10\n",
      "0s - loss:  0.4130 - mse:  0.4130 - val_mse:  0.4307\n",
      "Epoch 4/10\n",
      "0s - loss:  0.3521 - mse:  0.3521 - val_mse:  0.3727\n",
      "Epoch 5/10\n",
      "0s - loss:  0.2977 - mse:  0.2977 - val_mse:  0.3181\n",
      "Epoch 6/10\n",
      "0s - loss:  0.2474 - mse:  0.2474 - val_mse:  0.2663\n",
      "Epoch 7/10\n",
      "0s - loss:  0.2007 - mse:  0.2007 - val_mse:  0.2179\n",
      "Epoch 8/10\n",
      "0s - loss:  0.1582 - mse:  0.1582 - val_mse:  0.1737\n",
      "Epoch 9/10\n",
      "0s - loss:  0.1206 - mse:  0.1206 - val_mse:  0.1344\n",
      "Epoch 10/10\n",
      "0s - loss:  0.0886 - mse:  0.0886 - val_mse:  0.1007\n",
      "CPU times: user 626 ms, sys: 46.3 ms, total: 673 ms\n",
      "Wall time: 727 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(SEED)\n",
    "matrix_1, matrix_2 = calculate_rating_matrices(data_loader, real_dataset, syn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5f811bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.346836</td>\n",
       "      <td>0.338359</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.337266</td>\n",
       "      <td>0.347657</td>\n",
       "      <td>0.327909</td>\n",
       "      <td>0.347032</td>\n",
       "      <td>0.347389</td>\n",
       "      <td>0.327288</td>\n",
       "      <td>0.345246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317865</td>\n",
       "      <td>0.348191</td>\n",
       "      <td>0.346392</td>\n",
       "      <td>0.337118</td>\n",
       "      <td>0.327928</td>\n",
       "      <td>0.337685</td>\n",
       "      <td>0.337359</td>\n",
       "      <td>0.347435</td>\n",
       "      <td>0.317859</td>\n",
       "      <td>0.347308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348118</td>\n",
       "      <td>0.338478</td>\n",
       "      <td>0.348816</td>\n",
       "      <td>0.338067</td>\n",
       "      <td>0.348511</td>\n",
       "      <td>0.328199</td>\n",
       "      <td>0.347718</td>\n",
       "      <td>0.348001</td>\n",
       "      <td>0.327929</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318365</td>\n",
       "      <td>0.348809</td>\n",
       "      <td>0.346925</td>\n",
       "      <td>0.337883</td>\n",
       "      <td>0.328507</td>\n",
       "      <td>0.338424</td>\n",
       "      <td>0.337587</td>\n",
       "      <td>0.348092</td>\n",
       "      <td>0.318359</td>\n",
       "      <td>0.347880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.347331</td>\n",
       "      <td>0.338617</td>\n",
       "      <td>0.348321</td>\n",
       "      <td>0.337941</td>\n",
       "      <td>0.348107</td>\n",
       "      <td>0.328418</td>\n",
       "      <td>0.347565</td>\n",
       "      <td>0.347823</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.345436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318233</td>\n",
       "      <td>0.348597</td>\n",
       "      <td>0.346888</td>\n",
       "      <td>0.337410</td>\n",
       "      <td>0.328347</td>\n",
       "      <td>0.338227</td>\n",
       "      <td>0.337455</td>\n",
       "      <td>0.348250</td>\n",
       "      <td>0.318227</td>\n",
       "      <td>0.347791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.347598</td>\n",
       "      <td>0.338532</td>\n",
       "      <td>0.348653</td>\n",
       "      <td>0.337776</td>\n",
       "      <td>0.348349</td>\n",
       "      <td>0.328107</td>\n",
       "      <td>0.347555</td>\n",
       "      <td>0.347879</td>\n",
       "      <td>0.327491</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318076</td>\n",
       "      <td>0.348982</td>\n",
       "      <td>0.346569</td>\n",
       "      <td>0.337556</td>\n",
       "      <td>0.328376</td>\n",
       "      <td>0.338447</td>\n",
       "      <td>0.337295</td>\n",
       "      <td>0.347951</td>\n",
       "      <td>0.318069</td>\n",
       "      <td>0.347838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347968</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.348928</td>\n",
       "      <td>0.338017</td>\n",
       "      <td>0.348639</td>\n",
       "      <td>0.328346</td>\n",
       "      <td>0.347804</td>\n",
       "      <td>0.348125</td>\n",
       "      <td>0.327766</td>\n",
       "      <td>0.345410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318374</td>\n",
       "      <td>0.349239</td>\n",
       "      <td>0.346828</td>\n",
       "      <td>0.337905</td>\n",
       "      <td>0.328644</td>\n",
       "      <td>0.338677</td>\n",
       "      <td>0.337618</td>\n",
       "      <td>0.348128</td>\n",
       "      <td>0.318368</td>\n",
       "      <td>0.348082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.347766</td>\n",
       "      <td>0.339243</td>\n",
       "      <td>0.349456</td>\n",
       "      <td>0.338055</td>\n",
       "      <td>0.348833</td>\n",
       "      <td>0.328276</td>\n",
       "      <td>0.348026</td>\n",
       "      <td>0.348618</td>\n",
       "      <td>0.327801</td>\n",
       "      <td>0.345699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318450</td>\n",
       "      <td>0.349459</td>\n",
       "      <td>0.347035</td>\n",
       "      <td>0.337940</td>\n",
       "      <td>0.328876</td>\n",
       "      <td>0.339010</td>\n",
       "      <td>0.338059</td>\n",
       "      <td>0.348192</td>\n",
       "      <td>0.318444</td>\n",
       "      <td>0.348315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.337674</td>\n",
       "      <td>0.328865</td>\n",
       "      <td>0.338867</td>\n",
       "      <td>0.327937</td>\n",
       "      <td>0.338438</td>\n",
       "      <td>0.318254</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.338173</td>\n",
       "      <td>0.317875</td>\n",
       "      <td>0.335466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.338854</td>\n",
       "      <td>0.336999</td>\n",
       "      <td>0.327784</td>\n",
       "      <td>0.318575</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>0.327920</td>\n",
       "      <td>0.338032</td>\n",
       "      <td>0.308394</td>\n",
       "      <td>0.337948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.347751</td>\n",
       "      <td>0.339214</td>\n",
       "      <td>0.349382</td>\n",
       "      <td>0.337792</td>\n",
       "      <td>0.348742</td>\n",
       "      <td>0.328084</td>\n",
       "      <td>0.347849</td>\n",
       "      <td>0.348506</td>\n",
       "      <td>0.327671</td>\n",
       "      <td>0.345681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318432</td>\n",
       "      <td>0.349322</td>\n",
       "      <td>0.346916</td>\n",
       "      <td>0.338018</td>\n",
       "      <td>0.328783</td>\n",
       "      <td>0.338789</td>\n",
       "      <td>0.338247</td>\n",
       "      <td>0.347766</td>\n",
       "      <td>0.318426</td>\n",
       "      <td>0.348149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.347683</td>\n",
       "      <td>0.338199</td>\n",
       "      <td>0.348339</td>\n",
       "      <td>0.337412</td>\n",
       "      <td>0.348050</td>\n",
       "      <td>0.327731</td>\n",
       "      <td>0.347178</td>\n",
       "      <td>0.347532</td>\n",
       "      <td>0.327447</td>\n",
       "      <td>0.344810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318046</td>\n",
       "      <td>0.348353</td>\n",
       "      <td>0.346466</td>\n",
       "      <td>0.337636</td>\n",
       "      <td>0.328087</td>\n",
       "      <td>0.337828</td>\n",
       "      <td>0.337528</td>\n",
       "      <td>0.347274</td>\n",
       "      <td>0.318040</td>\n",
       "      <td>0.347379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.347766</td>\n",
       "      <td>0.339243</td>\n",
       "      <td>0.349456</td>\n",
       "      <td>0.338055</td>\n",
       "      <td>0.348833</td>\n",
       "      <td>0.328276</td>\n",
       "      <td>0.348026</td>\n",
       "      <td>0.348618</td>\n",
       "      <td>0.327801</td>\n",
       "      <td>0.345699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318450</td>\n",
       "      <td>0.349459</td>\n",
       "      <td>0.347035</td>\n",
       "      <td>0.337940</td>\n",
       "      <td>0.328876</td>\n",
       "      <td>0.339010</td>\n",
       "      <td>0.338059</td>\n",
       "      <td>0.348192</td>\n",
       "      <td>0.318444</td>\n",
       "      <td>0.348315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id        0         1         2         3         4         5         6   \\\n",
       "user_id                                                                         \n",
       "0        0.346836  0.338359  0.347897  0.337266  0.347657  0.327909  0.347032   \n",
       "1        0.348118  0.338478  0.348816  0.338067  0.348511  0.328199  0.347718   \n",
       "2        0.347331  0.338617  0.348321  0.337941  0.348107  0.328418  0.347565   \n",
       "3        0.347598  0.338532  0.348653  0.337776  0.348349  0.328107  0.347555   \n",
       "4        0.347968  0.338774  0.348928  0.338017  0.348639  0.328346  0.347804   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "95       0.347766  0.339243  0.349456  0.338055  0.348833  0.328276  0.348026   \n",
       "96       0.337674  0.328865  0.338867  0.327937  0.338438  0.318254  0.337729   \n",
       "97       0.347751  0.339214  0.349382  0.337792  0.348742  0.328084  0.347849   \n",
       "98       0.347683  0.338199  0.348339  0.337412  0.348050  0.327731  0.347178   \n",
       "99       0.347766  0.339243  0.349456  0.338055  0.348833  0.328276  0.348026   \n",
       "\n",
       "item_id        7         8         9   ...        90        91        92  \\\n",
       "user_id                                ...                                 \n",
       "0        0.347389  0.327288  0.345246  ...  0.317865  0.348191  0.346392   \n",
       "1        0.348001  0.327929  0.344994  ...  0.318365  0.348809  0.346925   \n",
       "2        0.347823  0.327830  0.345436  ...  0.318233  0.348597  0.346888   \n",
       "3        0.347879  0.327491  0.345175  ...  0.318076  0.348982  0.346569   \n",
       "4        0.348125  0.327766  0.345410  ...  0.318374  0.349239  0.346828   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "95       0.348618  0.327801  0.345699  ...  0.318450  0.349459  0.347035   \n",
       "96       0.338173  0.317875  0.335466  ...  0.308400  0.338854  0.336999   \n",
       "97       0.348506  0.327671  0.345681  ...  0.318432  0.349322  0.346916   \n",
       "98       0.347532  0.327447  0.344810  ...  0.318046  0.348353  0.346466   \n",
       "99       0.348618  0.327801  0.345699  ...  0.318450  0.349459  0.347035   \n",
       "\n",
       "item_id        93        94        95        96        97        98        99  \n",
       "user_id                                                                        \n",
       "0        0.337118  0.327928  0.337685  0.337359  0.347435  0.317859  0.347308  \n",
       "1        0.337883  0.328507  0.338424  0.337587  0.348092  0.318359  0.347880  \n",
       "2        0.337410  0.328347  0.338227  0.337455  0.348250  0.318227  0.347791  \n",
       "3        0.337556  0.328376  0.338447  0.337295  0.347951  0.318069  0.347838  \n",
       "4        0.337905  0.328644  0.338677  0.337618  0.348128  0.318368  0.348082  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "95       0.337940  0.328876  0.339010  0.338059  0.348192  0.318444  0.348315  \n",
       "96       0.327784  0.318575  0.328461  0.327920  0.338032  0.308394  0.337948  \n",
       "97       0.338018  0.328783  0.338789  0.338247  0.347766  0.318426  0.348149  \n",
       "98       0.337636  0.328087  0.337828  0.337528  0.347274  0.318040  0.347379  \n",
       "99       0.337940  0.328876  0.339010  0.338059  0.348192  0.318444  0.348315  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-blade",
   "metadata": {},
   "source": [
    "## Create response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee71b986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modules.trainers' from '/Users/vldpro/Workspace/university/recsys/modules/trainers.py'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from modules import models, evaluator, trainers, utils\n",
    "importlib.reload(models)\n",
    "importlib.reload(evaluator)\n",
    "importlib.reload(trainers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c73a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFunction:\n",
    "    def __init__(self, deepfm_matrix_1, deepfm_matrix_2):\n",
    "        assert deepfm_matrix_1.shape == deepfm_matrix_2.shape\n",
    "        self._deepfm_matrix_1 = deepfm_matrix_1\n",
    "        self._deepfm_matrix_2 = deepfm_matrix_2\n",
    "        \n",
    "    def __call__(self, a1: float, a2: float):\n",
    "        a3 = max(0.0, 1 - a1 - a2)\n",
    "        return (\n",
    "            a1 * self._deepfm_matrix_1\n",
    "            + a2 * self._deepfm_matrix_2\n",
    "            + a3 * npr.normal(0, 1, size=self._deepfm_matrix_1.shape)\n",
    "        )\n",
    "    \n",
    "\n",
    "resp_function = evaluator.ResponseFunctionConfig(\n",
    "    factory=ResponseFunction, args=[matrix_1, matrix_2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b9702",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "348237df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.Subprocess started.Subprocess started.\n",
      "Subprocess started.\n",
      "\n",
      "\n",
      "Load data finished. Number of users: 100 Number of items: 100\n",
      "Load data finished. Number of users: 100 Number of items: 100\n",
      "Load data finished. Number of users: 100Load data finished. Number of users: Number of items: 100 \n",
      "100 Number of items: 100\n",
      "IAutoRec.IAutoRec.IAutoRec.\n",
      "\n",
      "\n",
      "IAutoRec.\n",
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/modules/models.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/modules/models.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/modules/models.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/modules/models.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/modules/models.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/modules/models.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/modules/models.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vldpro/Workspace/university/recsys/modules/models.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000; Epoch: 0000; Epoch: 0000; Epoch: 0000; RMSE:0.9112774094228897; MAE:0.7271760487266331RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "\n",
      "Epoch: 0003; Epoch: 0003; RMSE:0.9112774094228897; MAE:0.7271760487266331RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "\n",
      "RMSE:0.9917435703405726; MAE:0.7714118467206817Epoch: 0003; \n",
      "Epoch: 0006; RMSE:0.9917435703405726; MAE:0.7714118467206817RMSE:0.6987835147413282; MAE:0.553635586223501Epoch: 0006; \n",
      "Epoch: 0009; RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "\n",
      "Epoch: 0012; Epoch: 0006; RMSE:0.7805905768541495; MAE:0.6147580099384602RMSE:0.9112774094228897; MAE:0.7271760487266331\n",
      "RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "Epoch: 0003; \n",
      "Epoch: 0009; Epoch: 0009; RMSE:0.6987835147413282; MAE:0.553635586223501RMSE:0.9112774094228897; MAE:0.7271760487266331\n",
      "RMSE:0.7805905768541495; MAE:0.6147580099384602Epoch: 0012; \n",
      "\n",
      "Epoch: 0006; RMSE:0.9917435703405726; MAE:0.7714118467206817Epoch: 0012; \n",
      "Epoch: 0015; RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "RMSE:0.9112774094228897; MAE:0.7271760487266331Epoch: 0009; \n",
      "Epoch: 0015; RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "Epoch: 0012; RMSE:0.6987835147413282; MAE:0.553635586223501RMSE:0.9917435703405726; MAE:0.7714118467206817RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "\n",
      "\n",
      "Epoch: 0015; Epoch: 0015; Epoch: 0018; RMSE:0.7805905768541495; MAE:0.6147580099384602RMSE:0.9112774094228897; MAE:0.7271760487266331\n",
      "RMSE:0.6987835147413282; MAE:0.553635586223501Epoch: 0018; \n",
      "Epoch: 0018; RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "RMSE:0.9112774094228897; MAE:0.7271760487266331\n",
      "Epoch: 0021; \n",
      "Epoch: 0021; Epoch: 0018; RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "Epoch: 0024; RMSE:0.6987835147413282; MAE:0.553635586223501RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "Epoch: 0021; RMSE:0.9112774094228897; MAE:0.7271760487266331RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "\n",
      "Epoch: 0024; Epoch: 0021; RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "\n",
      "Epoch: 0024; Epoch: 0027; RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "RMSE:0.6987835147413282; MAE:0.553635586223501RMSE:0.9112774094228897; MAE:0.7271760487266331Epoch: 0030; RMSE:0.7805905768541495; MAE:0.6147580099384602RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "\n",
      "Epoch: 0033; \n",
      "Epoch: 0027; \n",
      "Epoch: 0024; Epoch: 0027; RMSE:0.9112774094228897; MAE:0.7271760487266331RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "\n",
      "Epoch: 0030; Epoch: 0030; RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "RMSE:0.9112774094228897; MAE:0.7271760487266331Epoch: 0027; \n",
      "Epoch: 0033; RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "RMSE:0.6987835147413282; MAE:0.553635586223501Epoch: 0036; RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "Epoch: 0030; \n",
      "RMSE:0.9917435703405726; MAE:0.7714118467206817Epoch: 0033; \n",
      "Epoch: 0039; RMSE:0.9112774094228897; MAE:0.7271760487266331RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "Epoch: 0033; \n",
      "Epoch: 0036; RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "RMSE:0.9917435703405726; MAE:0.7714118467206817RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "Epoch: 0036; Epoch: 0036; RMSE:0.9112774094228897; MAE:0.7271760487266331\n",
      "\n",
      "Epoch: 0039; Epoch: 0042; RMSE:0.9112774094228897; MAE:0.7271760487266331\n",
      "Epoch: 0042; RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "Epoch: 0039; RMSE:0.7805905768541495; MAE:0.6147580099384602RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "Epoch: 0045; \n",
      "RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "Epoch: 0042; Epoch: 0039; RMSE:0.9112774094228897; MAE:0.7271760487266331RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "RMSE:0.9917435703405726; MAE:0.7714118467206817Epoch: 0045; \n",
      "Epoch: 0045; \n",
      "Epoch: 0048; RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "RMSE:0.6987835147413282; MAE:0.553635586223501Epoch: 0042; RMSE:0.9112774094228897; MAE:0.7271760487266331RMSE:0.9917435703405726; MAE:0.7714118467206817\n",
      "\n",
      "\n",
      "Epoch: 0048; Epoch: 0048; RMSE:0.9112774094228897; MAE:0.7271760487266331\n",
      "RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "Epoch: 0045; RMSE:0.6987835147413282; MAE:0.553635586223501\n",
      "RMSE:0.7805905768541495; MAE:0.6147580099384602\n",
      "Load data finished. Number of users:Epoch: 0048;  100 Number of items: RMSE:0.7805905768541495; MAE:0.6147580099384602100\n",
      "\n",
      "IAutoRec.\n",
      "Load data finished. Number of users: 100Load data finished. Number of users:  Number of items:100 100 \n",
      "Number of items: 100IAutoRec.\n",
      "\n",
      "Load data finished. Number of users: 100 Number of items:IAutoRec.\n",
      " 100\n",
      "IAutoRec.\n",
      "Epoch: 0000; "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_evaluators = [\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.AutoRecTrainTestExecutor,\n",
    "        args={\"config\": {\"epoch\": 50}},\n",
    "        model_name=\"autorec\"\n",
    "    ),\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.SvdTrainTestExecutor,\n",
    "        args={},\n",
    "        model_name=\"svd\"\n",
    "    ),\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.KnnTrainTestExecutor,\n",
    "        args={},\n",
    "        model_name=\"knn\"\n",
    "    )\n",
    "]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "_evaluator = evaluator.Evaluator(resp_function, n_proc=4)\n",
    "_res = _evaluator.evaluate(\n",
    "    _evaluators, \n",
    "    a_sample_rate=10,\n",
    "    test_size=0.1,\n",
    "    sample_sizes=[0.1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4755a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63ba90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res.to_csv(generate_filename(base=\"evalution_result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-dialogue",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52b397d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_surface = utils.group_points_by_minimum_error(_res)\n",
    "error_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27702434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from modules import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "for ss in [0.1]:\n",
    "    fig = px.scatter_3d(\n",
    "        error_surface[error_surface[\"sample_size\"] == ss], \n",
    "        x='a1', \n",
    "        y='a2', \n",
    "        z='rmse',\n",
    "        size=\"rmse\",\n",
    "        size_max=18, \n",
    "        opacity=1,\n",
    "        color=\"model_name\",\n",
    "        color_continuous_scale=px.colors.sequential.thermal[::-1]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "    )\n",
    "\n",
    "    fig.show(\"notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "fb17c3c70aa2daba89de097746222c240ddefaef361ffa09e744913d93ac8208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
