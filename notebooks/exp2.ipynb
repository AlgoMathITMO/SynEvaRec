{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mysterious-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import random as npr\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3ed26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "BOOKS_DATASET_PATH = \"books_dataset_cleaned.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-yugoslavia",
   "metadata": {},
   "source": [
    "## Load and transform restaurants data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3adefce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80942</th>\n",
       "      <td>6505</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>0671627759</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Janet Dailey</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369220</th>\n",
       "      <td>236700</td>\n",
       "      <td>31.224355</td>\n",
       "      <td>brazil</td>\n",
       "      <td>0345431553</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Robert Sheckley</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Del Rey Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138069</th>\n",
       "      <td>110160</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>0743206061</td>\n",
       "      <td>9</td>\n",
       "      <td>7.173913</td>\n",
       "      <td>Mary Higgins Clark</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Simon &amp;amp; Schuster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359883</th>\n",
       "      <td>212328</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>0852634692</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>E. Leadbeat</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>Hyperion Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348158</th>\n",
       "      <td>187517</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>1579547141</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>Jorge Cruise</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Rodale Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        Age Country        ISBN  book_rating  rating_Avg  \\\n",
       "80942      6505  56.000000     usa  0671627759            6    6.000000   \n",
       "369220   236700  31.224355  brazil  0345431553            5    5.000000   \n",
       "138069   110160  30.000000     usa  0743206061            9    7.173913   \n",
       "359883   212328  34.000000     usa  0852634692            6    6.000000   \n",
       "348158   187517  28.000000     usa  1579547141            9    9.000000   \n",
       "\n",
       "               Book_Author  Year_Of_Publication             Publisher  \n",
       "80942         Janet Dailey               1986.0                Pocket  \n",
       "369220     Robert Sheckley               1999.0         Del Rey Books  \n",
       "138069  Mary Higgins Clark               2003.0  Simon &amp; Schuster  \n",
       "359883         E. Leadbeat               1983.0        Hyperion Books  \n",
       "348158        Jorge Cruise               2003.0          Rodale Books  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset = pd.read_csv(BOOKS_DATASET_PATH)\n",
    "real_dataset = real_dataset.drop([\"Location\", \"rating_sum\", \"Book_Title\", \"Count_All_Rate\"], axis=1)\n",
    "real_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52f367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset[\"ISBN\"] = real_dataset[\"ISBN\"].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd4c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset[\"book_rating\"] = real_dataset[\"book_rating\"] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a105d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                  int64\n",
       "Age                    float64\n",
       "Country                 object\n",
       "ISBN                     int16\n",
       "book_rating            float64\n",
       "rating_Avg             float64\n",
       "Book_Author             object\n",
       "Year_Of_Publication    float64\n",
       "Publisher               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b91957a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80942</th>\n",
       "      <td>6505</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>8796</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Janet Dailey</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369220</th>\n",
       "      <td>236700</td>\n",
       "      <td>31.224355</td>\n",
       "      <td>brazil</td>\n",
       "      <td>2819</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Robert Sheckley</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Del Rey Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138069</th>\n",
       "      <td>110160</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>9971</td>\n",
       "      <td>0.9</td>\n",
       "      <td>7.173913</td>\n",
       "      <td>Mary Higgins Clark</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Simon &amp;amp; Schuster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359883</th>\n",
       "      <td>212328</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>11658</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>E. Leadbeat</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>Hyperion Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348158</th>\n",
       "      <td>187517</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>13282</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>Jorge Cruise</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Rodale Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255962</th>\n",
       "      <td>66942</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>malaysia</td>\n",
       "      <td>6438</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>Alexs D. Pate</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>DreamWorks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293114</th>\n",
       "      <td>98391</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>10524</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>Robyn Carr</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Mira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>33318</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>4360</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>Jane Hamilton</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Anchor Books/Doubleday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34331</th>\n",
       "      <td>144038</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>420</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.716981</td>\n",
       "      <td>Barbara Kingsolver</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293316</th>\n",
       "      <td>98391</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>10885</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>Jane Graves</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ivy Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        Age   Country   ISBN  book_rating  rating_Avg  \\\n",
       "80942      6505  56.000000       usa   8796          0.6    6.000000   \n",
       "369220   236700  31.224355    brazil   2819          0.5    5.000000   \n",
       "138069   110160  30.000000       usa   9971          0.9    7.173913   \n",
       "359883   212328  34.000000       usa  11658          0.6    6.000000   \n",
       "348158   187517  28.000000       usa  13282          0.9    9.000000   \n",
       "...         ...        ...       ...    ...          ...         ...   \n",
       "255962    66942  31.000000  malaysia   6438          0.5    7.000000   \n",
       "293114    98391  52.000000       usa  10524          0.8    8.000000   \n",
       "3430      33318  33.000000       usa   4360          0.8    7.000000   \n",
       "34331    144038  49.000000       usa    420          0.8    7.716981   \n",
       "293316    98391  52.000000       usa  10885          0.8    8.000000   \n",
       "\n",
       "               Book_Author  Year_Of_Publication               Publisher  \n",
       "80942         Janet Dailey               1986.0                  Pocket  \n",
       "369220     Robert Sheckley               1999.0           Del Rey Books  \n",
       "138069  Mary Higgins Clark               2003.0    Simon &amp; Schuster  \n",
       "359883         E. Leadbeat               1983.0          Hyperion Books  \n",
       "348158        Jorge Cruise               2003.0            Rodale Books  \n",
       "...                    ...                  ...                     ...  \n",
       "255962       Alexs D. Pate               1997.0              DreamWorks  \n",
       "293114          Robyn Carr               2004.0                    Mira  \n",
       "3430         Jane Hamilton               1999.0  Anchor Books/Doubleday  \n",
       "34331   Barbara Kingsolver               1994.0               Perennial  \n",
       "293316         Jane Graves               2002.0               Ivy Books  \n",
       "\n",
       "[19192 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d48daa",
   "metadata": {},
   "source": [
    "## Training DeepFM components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32d4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(*, base, ext=\"csv\"):\n",
    "    now = datetime.datetime.utcnow()\n",
    "    return \"exp2_\" + base + \"_\" + now.strftime(\"%d%m%y_%H%M%S\") + \".\" + ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63ace163",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_names = {\n",
    "    \"dense\": [\n",
    "        \"Age\",\n",
    "        \"rating_Avg\",\n",
    "        \"Year_Of_Publication\"\n",
    "    ],\n",
    "    \"sparse\": [\n",
    "        \"Book_Author\",\n",
    "        \"Country\",\n",
    "        \"Publisher\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b860145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from modules.models import DeepFmModel\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DeepFmInputDataset:\n",
    "    data: object\n",
    "    dnn_feats: object\n",
    "    linear_feats: object\n",
    "    feat_names: object\n",
    "\n",
    "\n",
    "class DeepFMDataLoader:\n",
    "    def __init__(self, *, sparse_features, dense_features):\n",
    "        self._sparse_feats = sparse_features\n",
    "        self._dense_feats = dense_features\n",
    "        \n",
    "    def load(self, dataset):\n",
    "        nn_input = pd.DataFrame()\n",
    "        nn_input[self._sparse_feats] = dataset[self._sparse_feats]\n",
    "        nn_input[self._dense_feats] = dataset[self._dense_feats]\n",
    "        \n",
    "        for feat in self._sparse_feats:\n",
    "            encoder = LabelEncoder()\n",
    "            nn_input[feat] = encoder.fit_transform(nn_input[feat])\n",
    "            \n",
    "        mms = MinMaxScaler(feature_range=(0,1))\n",
    "        nn_input[self._dense_feats] = mms.fit_transform(nn_input[self._dense_feats])\n",
    "        \n",
    "        # problems may be here\n",
    "        sparse_feature_columns = [\n",
    "            SparseFeat(feat, vocabulary_size=nn_input[feat].nunique(), embedding_dim=4) \n",
    "            for i, feat in enumerate(self._sparse_feats)\n",
    "        ]\n",
    "\n",
    "        dense_feature_columns = [DenseFeat(feat, 1,) for feat in self._dense_feats]\n",
    "        \n",
    "        dnn_feat_cols = sparse_feature_columns + dense_feature_columns\n",
    "        linear_feat_cols = sparse_feature_columns + dense_feature_columns\n",
    "        \n",
    "        feat_names = get_feature_names(linear_feat_cols + dnn_feat_cols)\n",
    "        input_dataset = DeepFmInputDataset(\n",
    "            data=nn_input,\n",
    "            dnn_feats=dnn_feat_cols,\n",
    "            linear_feats=linear_feat_cols,\n",
    "            feat_names=feat_names\n",
    "        )\n",
    "        return input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d96f968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rating_matrix(dataset, predicted_response):\n",
    "    result = pd.DataFrame()\n",
    "    result[\"rating\"] = predicted_response.reshape((len(predicted_response),))\n",
    "    result[\"user_id\"] = dataset[\"user_id\"]\n",
    "    result[\"item_id\"] = dataset[\"item_id\"]\n",
    "    matrix = result.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45814bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_feats(feats_a, feats_b):\n",
    "    assert len(feats_a) == len(feats_b)\n",
    "    merged = []\n",
    "    for feat_a, feat_b in zip(feats_a, feats_b):\n",
    "        if isinstance(feat_a, DenseFeat):\n",
    "            continue\n",
    "        if feat_a.vocabulary_size >= feat_b.vocabulary_size:\n",
    "            merged.append(feat_a)\n",
    "        else:\n",
    "            merged.append(feat_b)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e84c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deepfm(feats, feat_names, x, y):\n",
    "    deepfm = DeepFmModel(feats, feats, feat_names)\n",
    "    train_set, test_set = train_test_split(x, test_size=0.2)\n",
    "    deepfm.train(train_set, target_values=y[:len(train_set)])\n",
    "    return deepfm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39616565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_deepfm_model(*, data_loader, train_set, test_set):\n",
    "    nn_train_input = data_loader.load(train_set)\n",
    "    nn_test_input = data_loader.load(test_set)\n",
    "    y = train_set[\"book_rating\"].values\n",
    "    \n",
    "    merged_feats = merge_feats(nn_train_input.dnn_feats, nn_test_input.dnn_feats)\n",
    "    deepfm = train_deepfm(merged_feats, nn_train_input.feat_names, x=nn_train_input.data, y=y)\n",
    "    return deepfm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a20fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset):\n",
    "    n = len(dataset)\n",
    "    mid = int(n / 2)\n",
    "    return dataset[:mid], dataset[mid:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3635e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.tabular import CTGAN, GaussianCopula, CopulaGAN\n",
    "import datetime\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def fit_syn_generator(df):\n",
    "    model = CTGAN(verbose=True, epochs=10)\n",
    "    df = df.astype(\"int64\", errors=\"ignore\") # Convert all numbers to int64\n",
    "    model.fit(df.copy())\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_worker(args):\n",
    "    dataset, name = args\n",
    "    generator = fit_syn_generator(dataset)\n",
    "    generator.save(generate_filename(base=name, ext=\"bin\"))\n",
    "    return generator\n",
    "\n",
    "\n",
    "def fit_parallel(real_dataset):\n",
    "    users = real_dataset[[\"user_id\", \"Age\", \"Country\"]].drop_duplicates().drop(\"user_id\", axis=1)\n",
    "    items = real_dataset[\n",
    "        [\"ISBN\", \"Book_Author\", \"Publisher\", \"rating_Avg\", \"Year_Of_Publication\"]\n",
    "    ].drop_duplicates().drop(\"ISBN\", axis=1)\n",
    "    args = [\n",
    "        (users, \"users_generator\"),\n",
    "        (items, \"items_generator\")\n",
    "    ]\n",
    "    with Pool() as p:\n",
    "        generators = p.map(fit_worker, args)\n",
    "    return generators\n",
    "\n",
    "\n",
    "def fit_synthetic_generators(real_dataset):\n",
    "    users = real_dataset[[\"user_id\", \"Age\", \"Country\"]].drop_duplicates().drop(\"user_id\", axis=1)\n",
    "    items = real_dataset[\n",
    "        [\"ISBN\", \"Book_Author\", \"Publisher\", \"rating_Avg\", \"Year_Of_Publication\"]\n",
    "    ].drop_duplicates().drop(\"ISBN\", axis=1)\n",
    "    \n",
    "    users_generator = fit_syn_generator(users)\n",
    "    users_generator.save(generate_filename(base=\"users_generator\", ext=\"bin\"))\n",
    "    items_generator = fit_syn_generator(items)\n",
    "    users_generator.save(generate_filename(base=\"items_generator\", ext=\"bin\"))\n",
    "    return users_generator, items_generator\n",
    "\n",
    "\n",
    "def generate_synthetic_data(users_generator, items_generator, n_users=100, n_items=100):\n",
    "    syn_users = users_generator.sample(n_users)\n",
    "    syn_items = items_generator.sample(n_items)\n",
    "    syn_users[\"user_id\"] = range(len(syn_users))\n",
    "    syn_items[\"item_id\"] = range(len(syn_items))\n",
    "    syn_users[\"_merge_key\"] = syn_items[\"_merge_key\"] = 1\n",
    "    \n",
    "    syn_dataset = pd.merge(syn_items, syn_users, on=\"_merge_key\")\n",
    "    syn_dataset = syn_dataset.drop([\"_merge_key\"], axis=1)\n",
    "    return syn_dataset\n",
    "\n",
    "\n",
    "def measure_durations(fn, dataset, n, step=5):\n",
    "    measures = []\n",
    "    for i in range(step, n, step):\n",
    "        start = datetime.datetime.utcnow()\n",
    "        fn(dataset[:i])\n",
    "        duration = datetime.datetime.utcnow() - start\n",
    "        measures.append({\"n\": i, \"time\": duration.seconds})\n",
    "        print(f\"Duration {duration.seconds}\")\n",
    "    return pd.DataFrame(measures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e958bad0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  random_state=random_state).fit(X).labels_\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_components=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "/Users/vldpro/Workspace/university/recsys/.venv/lib/python3.7/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  3.5466,Loss D: -0.0026\n",
      "Epoch 1, Loss G:  6.3361,Loss D: -0.0011\n",
      "CPU times: user 66.2 ms, sys: 75.3 ms, total: 141 ms\n",
      "Wall time: 3.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(SEED)\n",
    "syn_sample = real_dataset.sample(frac=0.05)\n",
    "users_generator, items_generator = fit_parallel(syn_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41b25fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>rating_Avg</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>item_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eric Francis</td>\n",
       "      <td>Casterman</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>philippines</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eric Francis</td>\n",
       "      <td>Casterman</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>spain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eric Francis</td>\n",
       "      <td>Casterman</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>japan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric Francis</td>\n",
       "      <td>Casterman</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Francis</td>\n",
       "      <td>Casterman</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>philippines</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Book_Author  Publisher  rating_Avg  Year_Of_Publication  item_id  Age  \\\n",
       "0  Eric Francis  Casterman           4                 2000        0   76   \n",
       "1  Eric Francis  Casterman           4                 2000        0   42   \n",
       "2  Eric Francis  Casterman           4                 2000        0   32   \n",
       "3  Eric Francis  Casterman           4                 2000        0   37   \n",
       "4  Eric Francis  Casterman           4                 2000        0   25   \n",
       "\n",
       "          Country  user_id  \n",
       "0     philippines        0  \n",
       "1           spain        1  \n",
       "2           japan        2  \n",
       "3  united kingdom        3  \n",
       "4     philippines        4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "syn_dataset = generate_synthetic_data(users_generator, items_generator)\n",
    "syn_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1d01e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating_matrices(data_loader, real_dataset, syn_dataset):\n",
    "    p1, p2 = split_dataset(real_dataset)\n",
    "    deepfm_1 = pretrain_deepfm_model(data_loader=data_loader, train_set=p1, test_set=syn_dataset)\n",
    "    deepfm_2 = pretrain_deepfm_model(data_loader=data_loader, train_set=p2, test_set=syn_dataset)\n",
    "    nn_syn_dataset = data_loader.load(syn_dataset)\n",
    "    \n",
    "    y1 = deepfm_1.predict(nn_syn_dataset.data)\n",
    "    y2 = deepfm_2.predict(nn_syn_dataset.data)\n",
    "    \n",
    "    matrix_1 = to_rating_matrix(syn_dataset, y1)\n",
    "    matrix_2 = to_rating_matrix(syn_dataset, y2)\n",
    "    return matrix_1, matrix_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "656a4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DeepFMDataLoader(sparse_features=attributes_names[\"sparse\"], dense_features=attributes_names[\"dense\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89b23468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 1842 samples, validate on 461 samples, 8 steps per epoch\n",
      "Epoch 1/10\n",
      "0s - loss:  0.4412 - mse:  0.4241 - val_mse:  0.2681\n",
      "Epoch 2/10\n",
      "0s - loss:  0.1608 - mse:  0.1535 - val_mse:  0.0603\n",
      "Epoch 3/10\n",
      "0s - loss:  0.0389 - mse:  0.0387 - val_mse:  0.0458\n",
      "Epoch 4/10\n",
      "0s - loss:  0.0535 - mse:  0.0522 - val_mse:  0.0400\n",
      "Epoch 5/10\n",
      "0s - loss:  0.0342 - mse:  0.0334 - val_mse:  0.0345\n",
      "Epoch 6/10\n",
      "0s - loss:  0.0315 - mse:  0.0320 - val_mse:  0.0385\n",
      "Epoch 7/10\n",
      "0s - loss:  0.0304 - mse:  0.0300 - val_mse:  0.0341\n",
      "Epoch 8/10\n",
      "0s - loss:  0.0271 - mse:  0.0264 - val_mse:  0.0331\n",
      "Epoch 9/10\n",
      "0s - loss:  0.0256 - mse:  0.0253 - val_mse:  0.0334\n",
      "Epoch 10/10\n",
      "0s - loss:  0.0232 - mse:  0.0230 - val_mse:  0.0344\n",
      "cpu\n",
      "Train on 1842 samples, validate on 461 samples, 8 steps per epoch\n",
      "Epoch 1/10\n",
      "0s - loss:  0.3896 - mse:  0.3695 - val_mse:  0.1730\n",
      "Epoch 2/10\n",
      "0s - loss:  0.0902 - mse:  0.0846 - val_mse:  0.0395\n",
      "Epoch 3/10\n",
      "0s - loss:  0.0509 - mse:  0.0506 - val_mse:  0.0650\n",
      "Epoch 4/10\n",
      "0s - loss:  0.0493 - mse:  0.0466 - val_mse:  0.0396\n",
      "Epoch 5/10\n",
      "0s - loss:  0.0341 - mse:  0.0351 - val_mse:  0.0434\n",
      "Epoch 6/10\n",
      "0s - loss:  0.0358 - mse:  0.0356 - val_mse:  0.0405\n",
      "Epoch 7/10\n",
      "0s - loss:  0.0315 - mse:  0.0318 - val_mse:  0.0393\n",
      "Epoch 8/10\n",
      "0s - loss:  0.0301 - mse:  0.0306 - val_mse:  0.0393\n",
      "Epoch 9/10\n",
      "0s - loss:  0.0278 - mse:  0.0285 - val_mse:  0.0393\n",
      "Epoch 10/10\n",
      "0s - loss:  0.0255 - mse:  0.0253 - val_mse:  0.0395\n",
      "CPU times: user 2.13 s, sys: 64.5 ms, total: 2.19 s\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(SEED)\n",
    "nn_sample = real_dataset.sample(frac=0.3)\n",
    "matrix_1, matrix_2 = calculate_rating_matrices(data_loader, nn_sample, syn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5f811bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.758257</td>\n",
       "      <td>0.733744</td>\n",
       "      <td>0.725057</td>\n",
       "      <td>0.695541</td>\n",
       "      <td>0.750845</td>\n",
       "      <td>0.809182</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>0.775497</td>\n",
       "      <td>0.769044</td>\n",
       "      <td>0.673083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.667631</td>\n",
       "      <td>0.747353</td>\n",
       "      <td>0.764645</td>\n",
       "      <td>0.734191</td>\n",
       "      <td>0.754713</td>\n",
       "      <td>0.757430</td>\n",
       "      <td>0.764274</td>\n",
       "      <td>0.796554</td>\n",
       "      <td>0.720825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.756114</td>\n",
       "      <td>0.732610</td>\n",
       "      <td>0.724292</td>\n",
       "      <td>0.695347</td>\n",
       "      <td>0.748988</td>\n",
       "      <td>0.805469</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>0.772809</td>\n",
       "      <td>0.766858</td>\n",
       "      <td>0.673747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759087</td>\n",
       "      <td>0.668261</td>\n",
       "      <td>0.745434</td>\n",
       "      <td>0.762149</td>\n",
       "      <td>0.733042</td>\n",
       "      <td>0.752140</td>\n",
       "      <td>0.755305</td>\n",
       "      <td>0.761989</td>\n",
       "      <td>0.793645</td>\n",
       "      <td>0.719691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.725727</td>\n",
       "      <td>0.704152</td>\n",
       "      <td>0.696138</td>\n",
       "      <td>0.668497</td>\n",
       "      <td>0.719290</td>\n",
       "      <td>0.772267</td>\n",
       "      <td>0.694957</td>\n",
       "      <td>0.741370</td>\n",
       "      <td>0.736606</td>\n",
       "      <td>0.648504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728515</td>\n",
       "      <td>0.643148</td>\n",
       "      <td>0.715694</td>\n",
       "      <td>0.731397</td>\n",
       "      <td>0.704492</td>\n",
       "      <td>0.721103</td>\n",
       "      <td>0.725290</td>\n",
       "      <td>0.731558</td>\n",
       "      <td>0.762117</td>\n",
       "      <td>0.691297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.740540</td>\n",
       "      <td>0.718087</td>\n",
       "      <td>0.709906</td>\n",
       "      <td>0.681659</td>\n",
       "      <td>0.733780</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.708858</td>\n",
       "      <td>0.756662</td>\n",
       "      <td>0.751384</td>\n",
       "      <td>0.660927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743436</td>\n",
       "      <td>0.655542</td>\n",
       "      <td>0.730222</td>\n",
       "      <td>0.746409</td>\n",
       "      <td>0.718466</td>\n",
       "      <td>0.736223</td>\n",
       "      <td>0.739954</td>\n",
       "      <td>0.746404</td>\n",
       "      <td>0.777461</td>\n",
       "      <td>0.705198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.758257</td>\n",
       "      <td>0.733744</td>\n",
       "      <td>0.725057</td>\n",
       "      <td>0.695541</td>\n",
       "      <td>0.750845</td>\n",
       "      <td>0.809182</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>0.775497</td>\n",
       "      <td>0.769044</td>\n",
       "      <td>0.673083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.667631</td>\n",
       "      <td>0.747353</td>\n",
       "      <td>0.764645</td>\n",
       "      <td>0.734191</td>\n",
       "      <td>0.754713</td>\n",
       "      <td>0.757430</td>\n",
       "      <td>0.764274</td>\n",
       "      <td>0.796554</td>\n",
       "      <td>0.720825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.749341</td>\n",
       "      <td>0.726319</td>\n",
       "      <td>0.718022</td>\n",
       "      <td>0.689444</td>\n",
       "      <td>0.742418</td>\n",
       "      <td>0.798019</td>\n",
       "      <td>0.717088</td>\n",
       "      <td>0.765776</td>\n",
       "      <td>0.760143</td>\n",
       "      <td>0.668240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752312</td>\n",
       "      <td>0.662802</td>\n",
       "      <td>0.738857</td>\n",
       "      <td>0.755324</td>\n",
       "      <td>0.726720</td>\n",
       "      <td>0.745231</td>\n",
       "      <td>0.748671</td>\n",
       "      <td>0.755240</td>\n",
       "      <td>0.786641</td>\n",
       "      <td>0.713429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.757744</td>\n",
       "      <td>0.733611</td>\n",
       "      <td>0.725077</td>\n",
       "      <td>0.695714</td>\n",
       "      <td>0.750442</td>\n",
       "      <td>0.808132</td>\n",
       "      <td>0.724328</td>\n",
       "      <td>0.774833</td>\n",
       "      <td>0.768522</td>\n",
       "      <td>0.673548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760858</td>\n",
       "      <td>0.668031</td>\n",
       "      <td>0.746931</td>\n",
       "      <td>0.764020</td>\n",
       "      <td>0.734073</td>\n",
       "      <td>0.754060</td>\n",
       "      <td>0.756882</td>\n",
       "      <td>0.763725</td>\n",
       "      <td>0.795789</td>\n",
       "      <td>0.720670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.740539</td>\n",
       "      <td>0.718086</td>\n",
       "      <td>0.709904</td>\n",
       "      <td>0.681658</td>\n",
       "      <td>0.733779</td>\n",
       "      <td>0.788381</td>\n",
       "      <td>0.708857</td>\n",
       "      <td>0.756660</td>\n",
       "      <td>0.751383</td>\n",
       "      <td>0.660926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743435</td>\n",
       "      <td>0.655541</td>\n",
       "      <td>0.730221</td>\n",
       "      <td>0.746408</td>\n",
       "      <td>0.718464</td>\n",
       "      <td>0.736222</td>\n",
       "      <td>0.739953</td>\n",
       "      <td>0.746402</td>\n",
       "      <td>0.777460</td>\n",
       "      <td>0.705197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.740539</td>\n",
       "      <td>0.718086</td>\n",
       "      <td>0.709905</td>\n",
       "      <td>0.681658</td>\n",
       "      <td>0.733779</td>\n",
       "      <td>0.788381</td>\n",
       "      <td>0.708857</td>\n",
       "      <td>0.756660</td>\n",
       "      <td>0.751383</td>\n",
       "      <td>0.660927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743435</td>\n",
       "      <td>0.655541</td>\n",
       "      <td>0.730221</td>\n",
       "      <td>0.746408</td>\n",
       "      <td>0.718465</td>\n",
       "      <td>0.736222</td>\n",
       "      <td>0.739953</td>\n",
       "      <td>0.746403</td>\n",
       "      <td>0.777460</td>\n",
       "      <td>0.705197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.740539</td>\n",
       "      <td>0.718086</td>\n",
       "      <td>0.709905</td>\n",
       "      <td>0.681658</td>\n",
       "      <td>0.733780</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.708857</td>\n",
       "      <td>0.756661</td>\n",
       "      <td>0.751384</td>\n",
       "      <td>0.660927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743435</td>\n",
       "      <td>0.655541</td>\n",
       "      <td>0.730221</td>\n",
       "      <td>0.746409</td>\n",
       "      <td>0.718465</td>\n",
       "      <td>0.736222</td>\n",
       "      <td>0.739954</td>\n",
       "      <td>0.746403</td>\n",
       "      <td>0.777461</td>\n",
       "      <td>0.705197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id        0         1         2         3         4         5         6   \\\n",
       "user_id                                                                         \n",
       "0        0.758257  0.733744  0.725057  0.695541  0.750845  0.809182  0.724481   \n",
       "1        0.756114  0.732610  0.724292  0.695347  0.748988  0.805469  0.723354   \n",
       "2        0.725727  0.704152  0.696138  0.668497  0.719290  0.772267  0.694957   \n",
       "3        0.740540  0.718087  0.709906  0.681659  0.733780  0.788382  0.708858   \n",
       "4        0.758257  0.733744  0.725057  0.695541  0.750845  0.809182  0.724481   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "95       0.749341  0.726319  0.718022  0.689444  0.742418  0.798019  0.717088   \n",
       "96       0.757744  0.733611  0.725077  0.695714  0.750442  0.808132  0.724328   \n",
       "97       0.740539  0.718086  0.709904  0.681658  0.733779  0.788381  0.708857   \n",
       "98       0.740539  0.718086  0.709905  0.681658  0.733779  0.788381  0.708857   \n",
       "99       0.740539  0.718086  0.709905  0.681658  0.733780  0.788382  0.708857   \n",
       "\n",
       "item_id        7         8         9   ...        90        91        92  \\\n",
       "user_id                                ...                                 \n",
       "0        0.775497  0.769044  0.673083  ...  0.761500  0.667631  0.747353   \n",
       "1        0.772809  0.766858  0.673747  ...  0.759087  0.668261  0.745434   \n",
       "2        0.741370  0.736606  0.648504  ...  0.728515  0.643148  0.715694   \n",
       "3        0.756662  0.751384  0.660927  ...  0.743436  0.655542  0.730222   \n",
       "4        0.775497  0.769044  0.673083  ...  0.761500  0.667631  0.747353   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "95       0.765776  0.760143  0.668240  ...  0.752312  0.662802  0.738857   \n",
       "96       0.774833  0.768522  0.673548  ...  0.760858  0.668031  0.746931   \n",
       "97       0.756660  0.751383  0.660926  ...  0.743435  0.655541  0.730221   \n",
       "98       0.756660  0.751383  0.660927  ...  0.743435  0.655541  0.730221   \n",
       "99       0.756661  0.751384  0.660927  ...  0.743435  0.655541  0.730221   \n",
       "\n",
       "item_id        93        94        95        96        97        98        99  \n",
       "user_id                                                                        \n",
       "0        0.764645  0.734191  0.754713  0.757430  0.764274  0.796554  0.720825  \n",
       "1        0.762149  0.733042  0.752140  0.755305  0.761989  0.793645  0.719691  \n",
       "2        0.731397  0.704492  0.721103  0.725290  0.731558  0.762117  0.691297  \n",
       "3        0.746409  0.718466  0.736223  0.739954  0.746404  0.777461  0.705198  \n",
       "4        0.764645  0.734191  0.754713  0.757430  0.764274  0.796554  0.720825  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "95       0.755324  0.726720  0.745231  0.748671  0.755240  0.786641  0.713429  \n",
       "96       0.764020  0.734073  0.754060  0.756882  0.763725  0.795789  0.720670  \n",
       "97       0.746408  0.718464  0.736222  0.739953  0.746402  0.777460  0.705197  \n",
       "98       0.746408  0.718465  0.736222  0.739953  0.746403  0.777460  0.705197  \n",
       "99       0.746409  0.718465  0.736222  0.739954  0.746403  0.777461  0.705197  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-blade",
   "metadata": {},
   "source": [
    "## Create response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee71b986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modules.trainers' from '/Users/vldpro/Workspace/university/recsys/modules/trainers.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from modules import models, evaluator, trainers, utils\n",
    "importlib.reload(models)\n",
    "importlib.reload(evaluator)\n",
    "importlib.reload(trainers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c73a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFunction:\n",
    "    def __init__(self, deepfm_matrix_1, deepfm_matrix_2):\n",
    "        assert deepfm_matrix_1.shape == deepfm_matrix_2.shape\n",
    "        self._deepfm_matrix_1 = deepfm_matrix_1\n",
    "        self._deepfm_matrix_2 = deepfm_matrix_2\n",
    "        \n",
    "    def __call__(self, a1: float, a2: float):\n",
    "        a3 = max(0.0, 1 - a1 - a2)\n",
    "        return (\n",
    "            a1 * self._deepfm_matrix_1\n",
    "            + a2 * self._deepfm_matrix_2\n",
    "            + a3 * npr.normal(0, 1, size=self._deepfm_matrix_1.shape)\n",
    "        )\n",
    "    \n",
    "\n",
    "resp_function = evaluator.ResponseFunctionConfig(\n",
    "    factory=ResponseFunction, args=[matrix_1, matrix_2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b9702",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "348237df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_evaluators = [\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.AutoRecTrainTestExecutor,\n",
    "        args={\"config\": {\"epoch\": 50}},\n",
    "        model_name=\"autorec\"\n",
    "    ),\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.SvdTrainTestExecutor,\n",
    "        args={},\n",
    "        model_name=\"svd\"\n",
    "    ),\n",
    "    evaluator.TrainTestExecutorConfig(\n",
    "        factory=trainers.KnnTrainTestExecutor,\n",
    "        args={},\n",
    "        model_name=\"knn\"\n",
    "    )\n",
    "]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "_evaluator = evaluator.Evaluator(resp_function, n_proc=4)\n",
    "_res = _evaluator.evaluate(\n",
    "    _evaluators, \n",
    "    a_sample_rate=3,\n",
    "    test_size=0.1,\n",
    "    sample_sizes=[0.1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4755a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res.to_csv(generate_filename(base=\"evalution_result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-dialogue",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b397d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_surface = utils.group_points_by_minimum_error(_res)\n",
    "error_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27702434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from modules import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "for ss in [0.1]:\n",
    "    fig = px.scatter_3d(\n",
    "        error_surface[error_surface[\"sample_size\"] == ss], \n",
    "        x='a1', \n",
    "        y='a2', \n",
    "        z='rmse',\n",
    "        size=\"rmse\",\n",
    "        size_max=18, \n",
    "        opacity=1,\n",
    "        color=\"model_name\",\n",
    "        color_continuous_scale=px.colors.sequential.thermal[::-1]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "    )\n",
    "\n",
    "    fig.show(\"notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "fb17c3c70aa2daba89de097746222c240ddefaef361ffa09e744913d93ac8208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
